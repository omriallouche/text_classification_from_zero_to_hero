# Text Classification - From Zero to Hero
### Dr. Omri Allouche ()
### NLP Day, Tel Aviv, November 2019

This repository contains the presentation and notebooks of a workshop presented at the 1st NLP Day (http://nlpday.ml/), held in November 2019 in Tel Aviv, Israel by Dr. Omri Allouche (https://www.linkedin.com/in/omria/).  

Abstract:

**TEXT CLASSIFICATION: FROM ZERO TO HERO**
*Recent years have seen a major jump in state-of-the-art results on various NLP tasks, with the introduction of powerful transformer-based deep neural networks trained on huge corpora. But when attempting to build a text classifier for our own custom domain, what does it all mean for us? In this workshop, I'll walk you through building an effective text classifier using only a handful of labeled data points. We'll label data using active learning and guided search, evaluate the performance of our model and our labels, use weak learners and data programming with the Snorkel package and employ state-of-the-art models (e.g. BERT) to our own data. We'll discuss common pitfalls and eventually obtain a working, high quality text classifier in a matter of hours.*

Presentation:  
- [link](https://github.com/omriallouche/text_classification_from_zero_to_hero/blob/master/docs/NLP%20Day%20-%20Text%20Classification%20Zero%20to%20Hero.pdf)

Notebooks:
1.  [Bag of Words and Tf-Idf](notebooks/1_bow_tfidf.ipynb)  
2.  [Word embeddings](notebooks/2_word_embeddings.ipynb)  
2a. [Optional: Train word embeddings](notebooks/2a_optional_train_word_embeddings.ipynb)  
2b. [Optional: Advanced sentence embedding methods in Flair](notebooks/2b_optional_advanced_sentence_embedding_methods_in_flair.ipynb)  
3.  [Contextual embeddings with ELMo](notebooks/3_elmo.ipynb)  
3a. [Optional: Contextual word vectors with BERT and stacking embeddings](3a_contextual_word_vectors_with_bert_and_stacking_embeddings.ipynb)  
4. [(Optional) Fine tuning a Language Model with ULMFiT](notebooks/4_optional_ulmfit.ipynb)  
5. [State-of-the-art Transformer with BERT](notebooks/5_bert.ipynb)

