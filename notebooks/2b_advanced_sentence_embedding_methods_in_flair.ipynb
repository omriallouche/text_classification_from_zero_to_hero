{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Sentece Embedding Methods in Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import Sentence, WordEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "sentence = Sentence('The grass is green .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Embedding using Flair's DocumentPoolEmbeddings Class\n",
    "We've used Flair to get embeddings for each word in the sentence. However, for text classification of the entire document, we need a way to integrate all these vectors into a single document embedding. There are several methods for that, and those interested would find this article useful - https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d\n",
    "\n",
    "The most basic element is averaging the word embedding into a single document embedding. In FLAIR, we do this using `DocumentPoolEmbeddings`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "document_embeddings = DocumentPoolEmbeddings([glove_embedding], pooling='mean')\n",
    "\n",
    "document_embeddings.embed(sentence)\n",
    "document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now check out the embedded sentence.\n",
    "print(sentence.get_embedding().shape)\n",
    "print(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### By using an RNN\n",
    "Alternatively, we can use an RNN that runs over the word embeddings. We will use the last hidden state as the document embedding. In this case it is very helpful to train the model using the true labels of our task, so that the RNN is optimized for our own data and task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "document_embeddings = DocumentRNNEmbeddings([glove_embedding], rnn_type='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an example sentence\n",
    "sentence = Sentence('The grass is green . And the sky is blue .')\n",
    "\n",
    "# embed the sentence with our document embedding\n",
    "document_embeddings.embed(sentence)\n",
    "\n",
    "# now check out the embedded sentence.\n",
    "print(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while `DocumentPoolEmbeddings` are immediately meaningful, `DocumentRNNEmbeddings` need to be tuned on the downstream task. This happens automatically in Flair if you train a new model with these embeddings. You can find an example of training a text classification model [here](/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md#training-a-text-classification-model). Once the model is trained, you can access the tuned DocumentRNNEmbeddings object directly from the classifier object and use it to embed sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DocumentRNNEmbeddings` have a number of hyper-parameters that can be tuned to improve learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ":param hidden_size: the number of hidden states in the rnn.\n",
    ":param rnn_layers: the number of layers for the rnn.\n",
    ":param reproject_words: boolean value, indicating whether to reproject the token embeddings in a separate linear\n",
    "layer before putting them into the rnn or not.\n",
    ":param reproject_words_dimension: output dimension of reprojecting token embeddings. If None the same output\n",
    "dimension as before will be taken.\n",
    ":param bidirectional: boolean value, indicating whether to use a bidirectional rnn or not.\n",
    ":param dropout: the dropout value to be used.\n",
    ":param word_dropout: the word dropout value to be used, if 0.0 word dropout is not used.\n",
    ":param locked_dropout: the locked dropout value to be used, if 0.0 locked dropout is not used.\n",
    ":param rnn_type: one of 'RNN' or 'LSTM'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training RNN on our own dataset - Loading dataset\n",
    "The simplest way to load our data in Flair is using a CSV file. You can learn about other method in [the documentation](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Corpus` for a text classification task, you need to have three files (train, dev, and test) in the \n",
    "above format located in one folder. This data folder structure could, for example, look like this for the IMDB task:\n",
    "```text\n",
    "/data/train.csv\n",
    "/data/val.csv\n",
    "/data/test.txt\n",
    "```\n",
    "Now create a `CSVClassificationCorpus` by pointing to this folder (`/data`). \n",
    "Thereby, each line in a file is converted to a `Sentence` object annotated with the labels.\n",
    "\n",
    "Attention: A text in a line can in fact have multiple sentences. Thus, a `Sentence` object is actually a `Document` and can actually consist of multiple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = 'data/'\n",
    "\n",
    "# column format indicating which columns hold the text and label(s). This is 1-based and not 0-based\n",
    "column_name_map = {3: \"text\", 2: \"label\"}\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True,\n",
    "                                      test_file='test.csv',\n",
    "                                      dev_file='val.csv',\n",
    "                                      train_file='train.csv')\n",
    "    \n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus.train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training RNN on our own dataset - Training our own model\n",
    "We're going to use an RNN to run through the contextual word embeddings we got from ELMo. We will use the hidden state at the end of the document as an embedding for the entire document. We will train the RNN on our labeled dataset, so that the final hidden state carries the most relevant information for our custom classification task.  \n",
    "\n",
    "For more information on training your own model using Flair, see [this tutorial](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change code below to fit our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# 3. make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('glove')]\n",
    "\n",
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('data/',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. plot weight traces (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_weights('data/weights.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
