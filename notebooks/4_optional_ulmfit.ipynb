{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "8U93_ToH1Y9z",
    "outputId": "87a1e0a6-f5ea-4e52-bcc8-189339df1159"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'text_classification_from_zero_to_hero'...\n",
      "remote: Enumerating objects: 107, done.\u001b[K\n",
      "remote: Total 107 (delta 0), reused 0 (delta 0), pack-reused 107\n",
      "Receiving objects: 100% (107/107), 51.67 MiB | 26.10 MiB/s, done.\n",
      "Resolving deltas: 100% (48/48), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/omriallouche/text_classification_from_zero_to_hero.git\n",
    "import os\n",
    "os.chdir('text_classification_from_zero_to_hero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jCkLdUY-1Y9_"
   },
   "source": [
    "# ULMFiT\n",
    "For more information I recommend this [excellent post](https://github.com/prrao87/tweet-stance-prediction/blob/master/ulmfit.ipynb).\n",
    "\n",
    "UlmFit consists of 3 steps:\n",
    "1. Training the language model on a general-domain corpus that captures high-level natural language features\n",
    "1. Fine-tuning the pre-trained language model on target task data\n",
    "1. Fine-tuning the classifier on target task data\n",
    "\n",
    "![ulmfit 3 steps](https://miro.medium.com/max/1616/1*w_qNXVr7N2OPCK5iMnHAVQ.png)\n",
    "\n",
    "Step 1 requires a lot of resources and was already performed by the creators of the FastAI package. For this task we will perform steps 2 and 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kVjQm0Z21Y-A"
   },
   "source": [
    "It puts together a few tricks for optimizing neural networks:\n",
    "1. Detection of initial Learning Rate. This is done by changing the learning rate in a wide range during the first steps of a neural network training, and keeping the rate that leads to the fastest decrease of the network loss. \n",
    "1. Cyclical learning rate changes, that aim to improve convergence speed while reducing the risk of getting stuck in a local minimum\n",
    "1. Transfer learning \n",
    "1. Integration of a large unlabeled dataset. This dataset is used to fine-tune the language model\n",
    "1. A rather simple but effective network architecture for the classifier. This NN architecture of 3 fully connected layers is supposed to provide solid performance on a large array of text classification tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQwQfSu-1Y-C"
   },
   "source": [
    "Using Ulmfit is rather simple\n",
    "\n",
    "The Note that we provide the data to the language model \n",
    "`bs` is the batch size.  \n",
    "We use the function `learner.lr_find()` to find the learning rate.  \n",
    "\n",
    "The function `learner.fit_one_cycle(PARAMETERS)` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B80dQb871Y-E"
   },
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "ITOunl321Y-J",
    "outputId": "2bb858a1-7a2f-4f20-a473-58a961295b3b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>num_chars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>i understand how israel captured the teritory ...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk.politics.guns</td>\n",
       "      <td>and im sure that is a great comfort to the wid...</td>\n",
       "      <td>298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rec.sport.hockey</td>\n",
       "      <td>have a look at ed belfour. belfour kicked gerr...</td>\n",
       "      <td>288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>talk.politics.mideast</td>\n",
       "      <td>deleted its noteworthy that the posts about th...</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rec.sport.baseball</td>\n",
       "      <td>recently, i heard the red sox on wrol a spanis...</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   label  ... num_chars\n",
       "0  talk.politics.mideast  ...       366\n",
       "1     talk.politics.guns  ...       298\n",
       "2       rec.sport.hockey  ...       288\n",
       "3  talk.politics.mideast  ...       300\n",
       "4     rec.sport.baseball  ...       365\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_val = pd.read_csv('../data/val.csv')\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fy6xJ1qt1Y-W"
   },
   "outputs": [],
   "source": [
    "df_train = df_train[['text', 'label']]\n",
    "df_val = df_val[['text', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4vkctHcG1Y-S"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "path = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iHurT1Yq1Y-m"
   },
   "source": [
    "## Fine-tuning a language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ULMFiT allows us to fine-tune its language model. This can lead to a significant improvement if our domain is very different than what the ULMFiT language model was trained on.  \n",
    "However, if our dataset is small, there's a risk of overfitting to our small dataset, with a \"catastrophic forgetting\" of the original language model (that generalizes better). Watch out for the difference between the train and validation loss, and make sure you don't over train the language model on your own data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the 20newsgroups dataset contains posts from many other newsgroups, one idea is to train a language model on data from other categories as well. We will not take this step here, but for this you will probably want to use texts from the file `data/20newsgroups.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm_train = pd.read_csv('../data/20newsgroups.csv')\n",
    "df_lm_valid = df_lm_all.sample(frac=0.2, random_state=0)\n",
    "df_lm_train = df_lm_train.drop(df_lm_valid.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue with our script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "qgM9ffyR1Y-x",
    "outputId": "1c54c2ce-defd-46c6-d91b-58742745bba2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "# Language model data\n",
    "print('Getting languge model data...')\n",
    "if not os.path.exists(path+'/data_lm_export.pkl'):\n",
    "    data_lm = TextLMDataBunch.from_df(\n",
    "        train_df=df_lm_train,\n",
    "        valid_df=df_lm_valid,\n",
    "        path=path, \n",
    "        label_cols='label', \n",
    "        text_cols='text')\n",
    "    data_lm.save('data_lm_export.pkl')\n",
    "else:\n",
    "    data_lm = load_data(path, 'data_lm_export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 279
    },
    "colab_type": "code",
    "id": "SQmjB7JC1Y_A",
    "outputId": "751e9fd6-686d-4a55-905e-6a3a726e9a8a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>idx</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>xxunk xxunk . i also root for frank thomas . xxbos yeah valentine , how many rings does clemens have ? xxunk like good old xxunk canadian logic . btw the only good thing i can say about the jays rotation this year is that it could have been worse . xxunk might have xxunk healthy . xxbos wetteland comes off the dl on april rd , and will be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>the league . this was kind of xxunk because they won the world series both the previous year and the following year . warren xxunk xxbos these people were very xxunk . any team that gets to the world series can win the world series , and anybody who ever xxunk a sweep is xxunk . if you put the best team in baseball in the series against the worst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>happens to be , well hey , the xxunk th starter . as for xxunk , its still early . xxbos discussing the fact that there were only players who had ever hit homeruns and stolen bases in their career while xxunk was batting . anyone have a list ? not as xxunk as it sounds to come up with all of them . i could nt . mays ,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>kind of xxunk all season ! how many home runs by xxunk ? just , right , you must be thinking of dean palmer or juan gonzalez both of texas who each had homers . i do nt know how many to follow , but he was for . xxbos mr . hernandez i apologize for the xxunk . i xxunk that i know that it is xxunk for some</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>. xxunk , xxunk xxunk stadium , was built years earlier . xxunk they do nt move the seats back for the few xxunk games but the xxunk lower xxunk used to move . it was all xxunk , which was pretty xxunk on bat day . its vastly better than it was before they xxunk it , though . back in the late s it was a xxunk .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_lm.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VRmWEASb1Y_Q"
   },
   "outputs": [],
   "source": [
    "lm_learn = language_model_learner(\n",
    "    data_lm, \n",
    "    drop_mult=0.7, \n",
    "    arch=AWD_LSTM)\n",
    "\n",
    "# On machines that support it, you can change to float16 precision. This leads to x2-x3 speedup on modern GPUs\n",
    "# lm_learn = lm_learn.to_fp16(clip=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fast.ai` package includes a method to find an optimal learning rate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "VdpGK0bu1Y_X",
    "outputId": "73a994ba-f14c-4d08-c167-a200905d0612"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nySkRiIgkuf8PzJPo5T/8NwcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Find the optimal learning rate\n",
    "lm_learn.lr_find(start_lr=1e-07, end_lr=10)\n",
    "# Plot a graph for detecting the optimal learning rate\n",
    "lm_learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "axZ8mDja1Y_b"
   },
   "source": [
    "We now can choose the learning rate from the plot above. We want a value that is a bit lower than the lowest point. 2e-1 seems to be a good value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N_pVizUE1Y_c"
   },
   "outputs": [],
   "source": [
    "lr = 1e-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZN4H3RJ1Y_n"
   },
   "source": [
    "We can test the language model by generating a few words following a seeding sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learn.predict(\"The problem with this is\", n_words=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "colab_type": "code",
    "id": "zOgW-Oo41Y_j",
    "outputId": "a9d27371-6e8a-4e18-ccc6-f8088b6a07e7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5.334176</td>\n",
       "      <td>4.628334</td>\n",
       "      <td>0.189286</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train the learner object\n",
    "lm_learn.fit_one_cycle(cyc_len=1, max_lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check how things change after one epoch of LM training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "-3Xpa4P_1Y_p",
    "outputId": "d3ae932d-5b27-4b98-a2cd-b51e5be0359f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The problem with this is that local hockey is so small on my grasp that it seems that everyone else in this lineup is treated to the real abc telecast while only the people on rogers tv in on their nowhere , so what you'"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_learn.predict(\"The problem with this is\", n_words=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's continue training the LM for 5 more cycles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "ii-ZpPg61Y_z",
    "outputId": "80503b13-7e89-4295-c7b3-5dd6864f3948"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.002279</td>\n",
       "      <td>5.028047</td>\n",
       "      <td>0.202009</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.978512</td>\n",
       "      <td>5.148430</td>\n",
       "      <td>0.200223</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.888426</td>\n",
       "      <td>5.330887</td>\n",
       "      <td>0.183259</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.854780</td>\n",
       "      <td>5.389820</td>\n",
       "      <td>0.192522</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.800180</td>\n",
       "      <td>5.407240</td>\n",
       "      <td>0.187277</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.741526</td>\n",
       "      <td>5.373962</td>\n",
       "      <td>0.178125</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.688714</td>\n",
       "      <td>5.431108</td>\n",
       "      <td>0.180804</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.628530</td>\n",
       "      <td>5.413410</td>\n",
       "      <td>0.183705</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.579777</td>\n",
       "      <td>5.379051</td>\n",
       "      <td>0.181585</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.536121</td>\n",
       "      <td>5.373295</td>\n",
       "      <td>0.183147</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lm_learn.fit_one_cycle(cyc_len=5, max_lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dQkyf73M1ZAA"
   },
   "outputs": [],
   "source": [
    "# Save the model to disk. We will need it for the text classifier later\n",
    "lm_learn.save_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Twck-uFi1ZAE"
   },
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "IQNHJNxE1ZAF",
    "outputId": "ff29644e-ee3d-4984-8c45-bb9ac36c72c2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:292: UserWarning: Couldn't retrieve source code for container of type CrossEntropyLoss. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(path+'/data_clas.pkl'):\n",
    "    data_clas = load_data(path, 'data_clas.pkl', bs=batch_size)\n",
    "else:\n",
    "    data_clas = TextClasDataBunch.from_df(\n",
    "        path=path,\n",
    "        train_df=df_trn, \n",
    "        valid_df=df_val,\n",
    "        label_cols='label', \n",
    "        text_cols='text', \n",
    "        vocab=data_lm.train_ds.vocab, \n",
    "        bs=batch_size)    \n",
    "    data_clas.save('data_clas.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "pXoZsr1g1ZAO",
    "outputId": "95e88b46-5687-4028-90e5-6398a1f473bc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (356 items)\n",
       "x: TextList\n",
       "xxbos i understand how israel xxunk the xxunk and xxunk that it is its right to annex it . i ca nt xxunk understand why it has to deal with xxunk much the same way jews were treated before the holocaust the final xxunk by xxunk . what i xxunk do nt get is why the u.s . has to xxunk the xxunk of such a xxunk xxunk of human rights . just wondering,xxbos and i m sure that is a great xxunk to the xxunk and children of those xxunk , beaten and burned to death . the real question is , did the xxunk rate in england go down , after they xxunk gun control xxunk ? if you look at the xxunk before and after their first such law in , you will see no effect .,xxbos have a look at xxunk xxunk . xxunk xxunk xxunk xxunk when the wings played the hawks a couple of xxunk ago . no penalty . no review . no xxunk . this was after he xxunk bob probert in the previous period . he was xxunk for that . xxunk xxunk . too bad he goes down so much !,xxbos deleted its xxunk that the xxunk about the west being evil etc are made not in some xxunk xxunk but from the west . if the west is so bad , why do they come here ? xxunk how they xxunk xxunk their rights to free xxunk , something completely xxunk in their own countries . xxunk,xxbos recently , i heard the red sox on xxunk a xxunk radio station . i thought it was so xxunk . the red sox in xxunk ? anyway , i want to find out how xxunk this is ? being a ny xxunk , i know the xxunk are on in xxunk but not the xxunk . i xxunk think that xxunk , xxunk , texas and xxunk are on in xxunk . are there any xxunk xxunk or is this a local\n",
       "y: CategoryList\n",
       "talk.politics.mideast,talk.politics.guns,rec.sport.hockey,talk.politics.mideast,rec.sport.baseball\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (76 items)\n",
       "x: TextList\n",
       "xxbos imagine , you have been under seige for almost two months by an xxunk which you believe wants to kill you . suddenly , they xxunk tear gas into your building and xxunk xxunk in it with tanks . then a fire xxunk out . do you run outside to be xxunk , or stay and face your fate . check ethiopia vs. xxunk in wwii for some answers to that question .,xxbos in the interests of saving xxunk during this xxunk time of the year xxunk . the early xxunk of xxunk comments coming from a certain state whose name starts with xxunk and ends with a , why do nt you tell us something we do nt already know ? george,xxbos jagr has a higher , but francis has had more points . and take it from an xxunk observer , xxunk francis has had a much better season than xxunk jagr . this is not to take anything away from xxunk , who had a decent year although it did nt live up to the xxunk of some . dean,xxbos the injury is to his xxunk hand , which is good . xxunk , he may have some xxunk xxunk and may xxunk xxunk , which would xxunk him up for a while . apparently just a xxunk of some sort . he has nt been put on the dl , so its probably just xxunk .,xxbos well josh i agree with you to some xxunk your spelling xxunk . the xxunk always must win ! even if they kill every man women and child .. by god they must win at all costs .. this happens over and over and over in this country . lets make xxunk , get the xxunk press to cover up everything , let the officials take the xxunk for top xxunk stupidity xxunk .\n",
       "y: CategoryList\n",
       "talk.politics.guns,rec.sport.hockey,rec.sport.hockey,rec.sport.baseball,talk.politics.guns\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1896, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1896, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fd22055cd90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
       "learn: RNNLearner(data=TextClasDataBunch;\n",
       "\n",
       "Train: LabelList (356 items)\n",
       "x: TextList\n",
       "xxbos i understand how israel xxunk the xxunk and xxunk that it is its right to annex it . i ca nt xxunk understand why it has to deal with xxunk much the same way jews were treated before the holocaust the final xxunk by xxunk . what i xxunk do nt get is why the u.s . has to xxunk the xxunk of such a xxunk xxunk of human rights . just wondering,xxbos and i m sure that is a great xxunk to the xxunk and children of those xxunk , beaten and burned to death . the real question is , did the xxunk rate in england go down , after they xxunk gun control xxunk ? if you look at the xxunk before and after their first such law in , you will see no effect .,xxbos have a look at xxunk xxunk . xxunk xxunk xxunk xxunk when the wings played the hawks a couple of xxunk ago . no penalty . no review . no xxunk . this was after he xxunk bob probert in the previous period . he was xxunk for that . xxunk xxunk . too bad he goes down so much !,xxbos deleted its xxunk that the xxunk about the west being evil etc are made not in some xxunk xxunk but from the west . if the west is so bad , why do they come here ? xxunk how they xxunk xxunk their rights to free xxunk , something completely xxunk in their own countries . xxunk,xxbos recently , i heard the red sox on xxunk a xxunk radio station . i thought it was so xxunk . the red sox in xxunk ? anyway , i want to find out how xxunk this is ? being a ny xxunk , i know the xxunk are on in xxunk but not the xxunk . i xxunk think that xxunk , xxunk , texas and xxunk are on in xxunk . are there any xxunk xxunk or is this a local\n",
       "y: CategoryList\n",
       "talk.politics.mideast,talk.politics.guns,rec.sport.hockey,talk.politics.mideast,rec.sport.baseball\n",
       "Path: .;\n",
       "\n",
       "Valid: LabelList (76 items)\n",
       "x: TextList\n",
       "xxbos imagine , you have been under seige for almost two months by an xxunk which you believe wants to kill you . suddenly , they xxunk tear gas into your building and xxunk xxunk in it with tanks . then a fire xxunk out . do you run outside to be xxunk , or stay and face your fate . check ethiopia vs. xxunk in wwii for some answers to that question .,xxbos in the interests of saving xxunk during this xxunk time of the year xxunk . the early xxunk of xxunk comments coming from a certain state whose name starts with xxunk and ends with a , why do nt you tell us something we do nt already know ? george,xxbos jagr has a higher , but francis has had more points . and take it from an xxunk observer , xxunk francis has had a much better season than xxunk jagr . this is not to take anything away from xxunk , who had a decent year although it did nt live up to the xxunk of some . dean,xxbos the injury is to his xxunk hand , which is good . xxunk , he may have some xxunk xxunk and may xxunk xxunk , which would xxunk him up for a while . apparently just a xxunk of some sort . he has nt been put on the dl , so its probably just xxunk .,xxbos well josh i agree with you to some xxunk your spelling xxunk . the xxunk always must win ! even if they kill every man women and child .. by god they must win at all costs .. this happens over and over and over in this country . lets make xxunk , get the xxunk press to cover up everything , let the officials take the xxunk for top xxunk stupidity xxunk .\n",
       "y: CategoryList\n",
       "talk.politics.guns,rec.sport.hockey,rec.sport.hockey,rec.sport.baseball,talk.politics.guns\n",
       "Path: .;\n",
       "\n",
       "Test: None, model=SequentialRNN(\n",
       "  (0): MultiBatchEncoder(\n",
       "    (module): AWD_LSTM(\n",
       "      (encoder): Embedding(1896, 400, padding_idx=1)\n",
       "      (encoder_dp): EmbeddingDropout(\n",
       "        (emb): Embedding(1896, 400, padding_idx=1)\n",
       "      )\n",
       "      (rnns): ModuleList(\n",
       "        (0): WeightDropout(\n",
       "          (module): LSTM(400, 1152, batch_first=True)\n",
       "        )\n",
       "        (1): WeightDropout(\n",
       "          (module): LSTM(1152, 1152, batch_first=True)\n",
       "        )\n",
       "        (2): WeightDropout(\n",
       "          (module): LSTM(1152, 400, batch_first=True)\n",
       "        )\n",
       "      )\n",
       "      (input_dp): RNNDropout()\n",
       "      (hidden_dps): ModuleList(\n",
       "        (0): RNNDropout()\n",
       "        (1): RNNDropout()\n",
       "        (2): RNNDropout()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (1): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7fd22055cd90>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('.'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[...], layer_groups=[Sequential(\n",
       "  (0): Embedding(1896, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1896, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)\n",
       "alpha: 2.0\n",
       "beta: 1.0], layer_groups=[Sequential(\n",
       "  (0): Embedding(1896, 400, padding_idx=1)\n",
       "  (1): EmbeddingDropout(\n",
       "    (emb): Embedding(1896, 400, padding_idx=1)\n",
       "  )\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(400, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 1152, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): WeightDropout(\n",
       "    (module): LSTM(1152, 400, batch_first=True)\n",
       "  )\n",
       "  (1): RNNDropout()\n",
       "), Sequential(\n",
       "  (0): PoolingLinearClassifier(\n",
       "    (layers): Sequential(\n",
       "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (1): Dropout(p=0.27999999999999997, inplace=False)\n",
       "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): Dropout(p=0.1, inplace=False)\n",
       "      (6): Linear(in_features=50, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")], add_time=True, silent=False)"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \n",
    "classifier_learn = text_classifier_learner(data_clas, drop_mult=0.7, pretrained=False, arch=AWD_LSTM)\n",
    "# \n",
    "classifier_learn.load_encoder('ft_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "colab_type": "code",
    "id": "iDDxUYyf1ZAU",
    "outputId": "ebbc8c67-b2e6-4bd5-eabc-710c1b92e310"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFeC0ECilVIDTQqCUUgFOC4FSSgW4/wcdL6wY0XpsbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_learn.lr_find()\n",
    "classifier_learn.recorder.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2kK4TNm81ZAY"
   },
   "source": [
    "Let's set the learning rate based on the previous graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FFuq-lH11ZAe"
   },
   "outputs": [],
   "source": [
    "lr = 5e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "GIMxOiiT1ZAn",
    "outputId": "88072f08-76ac-4324-b515-963f9d12889b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.366192</td>\n",
       "      <td>1.259665</td>\n",
       "      <td>0.434211</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.125656</td>\n",
       "      <td>0.879517</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.949881</td>\n",
       "      <td>0.775755</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.830186</td>\n",
       "      <td>0.753873</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.744836</td>\n",
       "      <td>0.782417</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.674462</td>\n",
       "      <td>0.812261</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.601353</td>\n",
       "      <td>0.808525</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.565418</td>\n",
       "      <td>0.796480</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.528164</td>\n",
       "      <td>0.782703</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.493174</td>\n",
       "      <td>0.786243</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>00:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_learn.fit_one_cycle(10, lr, moms=(0.8,0.7), wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pV0xOy8m1ZAr"
   },
   "source": [
    "We'll now gradually unfreeze the layers, starting from the top layers and adding more layers every epoch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "colab_type": "code",
    "id": "erBnH07F1ZAt",
    "outputId": "c0023805-31ca-4e51-c4cb-dbc9ba1699f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.462353</td>\n",
       "      <td>0.810972</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>00:03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_learn.freeze_to(-2)\n",
    "lr /= 2\n",
    "classifier_learn.fit_one_cycle(1, slice(lr/(2.6**4),lr), moms=(0.8,0.7), wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "id": "N_SmJZiV1ZAx",
    "outputId": "7172642b-b6c0-4621-d16a-430d903631c3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.276166</td>\n",
       "      <td>0.825047</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.261642</td>\n",
       "      <td>0.828067</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.266998</td>\n",
       "      <td>0.832981</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.270807</td>\n",
       "      <td>0.826062</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.255189</td>\n",
       "      <td>0.829886</td>\n",
       "      <td>0.671053</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.243133</td>\n",
       "      <td>0.829157</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.227799</td>\n",
       "      <td>0.845982</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.220496</td>\n",
       "      <td>0.837691</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.215813</td>\n",
       "      <td>0.823293</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.218642</td>\n",
       "      <td>0.845948</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>00:04</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_learn.freeze_to(-3)\n",
    "lr /= 2\n",
    "classifier_learn.fit_one_cycle(10, slice(lr/(2.6**4),lr), moms=(0.8,0.7), wd=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "colab_type": "code",
    "id": "bImkrkZb1ZA3",
    "outputId": "94cb8e4f-04fc-48f7-c075-58f3000f2a5a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.535326</td>\n",
       "      <td>0.896815</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.487278</td>\n",
       "      <td>0.874851</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>00:05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier_learn.unfreeze()\n",
    "lr /= 5\n",
    "classifier_learn.fit_one_cycle(2, slice(lr/(2.6**4),lr), moms=(0.8,0.7), wd=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aSpEexPA1ZA7"
   },
   "source": [
    "Finally, let's save our classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PD-0m18K1ZA8"
   },
   "outputs": [],
   "source": [
    "classifier_learn.save('ft_clas')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zY9149Ff1ZA_"
   },
   "source": [
    "We can now make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HYbn0O2Q1ZBA"
   },
   "outputs": [],
   "source": [
    "pred_fwd,lbl_fwd = classifier_learn.get_preds(ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vQ2vimkh6wPM"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ulmfit.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
