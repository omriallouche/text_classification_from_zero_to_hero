{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ELMo\n",
    "ELMo learns contextualized word vectors by running the text through a deep recurrent network.  \n",
    "ELMo is actually an algorithm for unsupervised learning and does not make any use of the labels we have for our text classification task. The authors do show that contextualized word vectors obtained using ELMo increase text classification performance in a large array of tasks. Let's see if we see a significant gain in our case!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are good examples of using ELMo in both [the AllenNLP github repo](https://github.com/allenai/allennlp/blob/master/tutorials/how_to/elmo.md) and [this AnalyticsVidhya post](https://www.analyticsvidhya.com/blog/2019/03/learn-to-use-elmo-to-extract-features-from-text/?utm_source=blog&utm_medium=top-pretrained-models-nlp-article). In this guide we'll use the python package [Flair](https://github.com/zalandoresearch/flair) to get ELMo embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual word embeddings with ELMo in Flair\n",
    "In Flair, you init a `Sentence` object given the tokens seperated by spaces.  \n",
    "Sentence has a few useful attributes and methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: allennlp in c:\\programdata\\anaconda3\\lib\\site-packages (0.9.0)\n",
      "Requirement already satisfied: requests>=2.18 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (2.21.0)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (2.9.0)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.9)\n",
      "Requirement already satisfied: editdistance in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.5.3)\n",
      "Requirement already satisfied: flask-cors>=3.0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (3.0.8)\n",
      "Requirement already satisfied: unidecode in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.1.1)\n",
      "Requirement already satisfied: responses>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.10.6)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.2.1)\n",
      "Requirement already satisfied: conllu==1.3.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.3.1)\n",
      "Requirement already satisfied: flaky in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (3.6.1)\n",
      "Requirement already satisfied: ftfy in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (4.4.3)\n",
      "Requirement already satisfied: gevent>=1.3.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.4.0)\n",
      "Requirement already satisfied: flask>=1.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.0.2)\n",
      "Requirement already satisfied: word2number>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.1)\n",
      "Requirement already satisfied: tqdm>=4.19 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (4.31.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.20.3)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (2018.4)\n",
      "Requirement already satisfied: pytorch-transformers==1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.1.0)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (3.0.3)\n",
      "Requirement already satisfied: jsonpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.2)\n",
      "Requirement already satisfied: numpydoc>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.8.0)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (3.4)\n",
      "Requirement already satisfied: spacy<2.2,>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (2.1.8)\n",
      "Requirement already satisfied: pytest in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (4.3.1)\n",
      "Requirement already satisfied: overrides in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (2.0)\n",
      "Requirement already satisfied: torch>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.3.0+cpu)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.9.110)\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.6.2)\n",
      "Requirement already satisfied: sqlparse>=0.2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.3.0)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (1.16.2)\n",
      "Requirement already satisfied: parsimonious>=0.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from allennlp) (0.8.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.18->allennlp) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.18->allennlp) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.18->allennlp) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests>=2.18->allennlp) (1.24.1)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from h5py->allennlp) (1.12.0)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboardX>=1.2->allennlp) (3.8.0)\n",
      "Requirement already satisfied: html5lib in c:\\programdata\\anaconda3\\lib\\site-packages (from ftfy->allennlp) (1.0.1)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from ftfy->allennlp) (0.1.7)\n",
      "Requirement already satisfied: greenlet>=0.4.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
      "Requirement already satisfied: cffi>=1.11.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from gevent>=1.3.6->allennlp) (1.12.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
      "Requirement already satisfied: Werkzeug>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask>=1.0.2->allennlp) (0.14.1)\n",
      "Requirement already satisfied: click>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask>=1.0.2->allennlp) (7.0)\n",
      "Requirement already satisfied: Jinja2>=2.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from flask>=1.0.2->allennlp) (2.10)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-transformers==1.1.0->allennlp) (2017.4.5)\n",
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-transformers==1.1.0->allennlp) (0.1.83)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->allennlp) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->allennlp) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->allennlp) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->allennlp) (2.8.0)\n",
      "Requirement already satisfied: sphinx>=1.2.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from numpydoc>=0.8.0->allennlp) (1.8.5)\n",
      "Requirement already satisfied: singledispatch in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->allennlp) (3.4.0.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.2)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (7.0.8)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (0.2.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.2)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (0.28.0)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (0.9.6)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (2.0.1)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from spacy<2.2,>=2.1.0->allennlp) (0.0.7)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->allennlp) (1.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\omri\\appdata\\roaming\\python\\python37\\site-packages (from pytest->allennlp) (41.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->allennlp) (19.1.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->allennlp) (1.3.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->allennlp) (0.9.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->allennlp) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest->allennlp) (0.4.1)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->allennlp) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.110 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->allennlp) (1.12.234)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->allennlp) (0.9.4)\n",
      "Requirement already satisfied: webencodings in c:\\programdata\\anaconda3\\lib\\site-packages (from html5lib->ftfy->allennlp) (0.5.1)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.11.5->gevent>=1.3.6->allennlp) (2.19)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from Jinja2>=2.10->flask>=1.0.2->allennlp) (1.1.1)\n",
      "Requirement already satisfied: Pygments>=2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (2.3.1)\n",
      "Requirement already satisfied: docutils>=0.11 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (0.14)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.2.1)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (2.6.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
      "Requirement already satisfied: imagesize in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (19.0)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in c:\\programdata\\anaconda3\\lib\\site-packages (from sphinx>=1.2.3->numpydoc>=0.8.0->allennlp) (1.1.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in c:\\programdata\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: mpld3==0.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: regex in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (2017.4.5)\n",
      "Requirement already satisfied: langdetect in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.0.7)\n",
      "Requirement already satisfied: bpemb>=0.2.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (0.3.0)\n",
      "Requirement already satisfied: pytest>=3.6.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (4.3.1)\n",
      "Requirement already satisfied: torch>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.3.0+cpu)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.6.0)\n",
      "Requirement already satisfied: hyperopt>=0.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (0.2)\n",
      "Requirement already satisfied: sklearn in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (0.0)\n",
      "Requirement already satisfied: tabulate in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (0.8.5)\n",
      "Requirement already satisfied: pytorch-transformers>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.1.0)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (4.31.1)\n",
      "Requirement already satisfied: ipython==7.6.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (7.6.1)\n",
      "Requirement already satisfied: segtok>=1.5.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.5.7)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.20 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.24.1)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (1.2.6)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (3.0.3)\n",
      "Requirement already satisfied: gensim>=3.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (3.7.1)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from flair) (0.2.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from langdetect->flair) (1.12.0)\n",
      "Requirement already satisfied: sentencepiece in c:\\programdata\\anaconda3\\lib\\site-packages (from bpemb>=0.2.9->flair) (0.1.83)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from bpemb>=0.2.9->flair) (1.16.2)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from bpemb>=0.2.9->flair) (2.21.0)\n",
      "Requirement already satisfied: py>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\omri\\appdata\\roaming\\python\\python37\\site-packages (from pytest>=3.6.4->flair) (41.0.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=3.6.4->flair) (19.1.0)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
      "Requirement already satisfied: pluggy>=0.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=3.6.4->flair) (0.9.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=3.6.4->flair) (6.0.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from pytest>=3.6.4->flair) (0.4.1)\n",
      "Requirement already satisfied: bson in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (0.5.8)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (1.2.1)\n",
      "Requirement already satisfied: networkx==2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (2.2)\n",
      "Requirement already satisfied: cloudpickle in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (0.8.0)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from sklearn->flair) (0.20.3)\n",
      "Requirement already satisfied: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pytorch-transformers>=1.1.0->flair) (1.9.110)\n",
      "Requirement already satisfied: pickleshare in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (2.0.9)\n",
      "Requirement already satisfied: backcall in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: traitlets>=4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (4.3.2)\n",
      "Requirement already satisfied: jedi>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (0.13.3)\n",
      "Requirement already satisfied: decorator in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (4.4.0)\n",
      "Requirement already satisfied: pygments in c:\\programdata\\anaconda3\\lib\\site-packages (from ipython==7.6.1->flair) (2.3.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from deprecated>=1.2.4->flair) (1.10.11)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2.3->flair) (2.8.0)\n",
      "Requirement already satisfied: smart-open>=1.7.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim>=3.4.0->flair) (1.8.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.2.9->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.2.9->flair) (2019.3.9)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->bpemb>=0.2.9->flair) (2.8)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.110 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers>=1.1.0->flair) (1.12.234)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers>=1.1.0->flair) (0.2.1)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->pytorch-transformers>=1.1.0->flair) (0.9.4)\n",
      "Requirement already satisfied: wcwidth in c:\\programdata\\anaconda3\\lib\\site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython==7.6.1->flair) (0.1.7)\n",
      "Requirement already satisfied: parso>=0.3.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.3.4)\n",
      "Requirement already satisfied: boto>=2.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: bz2file in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.7.0->gensim>=3.4.0->flair) (0.98)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.110->boto3->pytorch-transformers>=1.1.0->flair) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install allennlp\n",
    "!pip install flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import Sentence\n",
    "sentence = Sentence('The grass is green .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also init a class of the desired embedding method. The `embed` method of this class gets a Sentence and adds to its tokens the relevant embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "torch.Size([3072])\n",
      "tensor([-0.3288,  0.2022, -0.5940,  ..., -1.2773,  0.3049,  0.2150])\n",
      "Token: 2 grass\n",
      "torch.Size([3072])\n",
      "tensor([ 0.2539, -0.2363,  0.5263,  ..., -0.7001,  0.8798,  1.4191])\n",
      "Token: 3 is\n",
      "torch.Size([3072])\n",
      "tensor([ 0.1915,  0.2300, -0.2894,  ..., -0.3626,  1.9066,  1.4520])\n",
      "Token: 4 green\n",
      "torch.Size([3072])\n",
      "tensor([ 0.1779,  0.1309, -0.1041,  ..., -0.1006,  1.6152,  0.3299])\n",
      "Token: 5 .\n",
      "torch.Size([3072])\n",
      "tensor([-0.8872, -0.2004, -1.0601,  ..., -0.0106, -0.0833,  0.0669])\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import ELMoEmbeddings\n",
    "\n",
    "# init embedding\n",
    "elmo_embedding = ELMoEmbeddings()\n",
    "\n",
    "elmo_embedding.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding.shape)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it yourself:** Now, compare the embeddings obtained using ELMo for the same word in different contexts. Are they equal or different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word sense disambiguation using ELMo\n",
    "**Try it yourself:** Let's also try to see how ELMo handles word sense disambiguation. Below are 6 sentences with 2 different meanings of the word `bank`. Try to see if ELMo vectors indeed separate the two meanings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    \"I was walking along the river bank\",\n",
    "    \"I saw a toad near the east bank of the river\",\n",
    "    \"We had a nice picnic by the bank\",\n",
    "    \"I need to deposit money from the bank\",\n",
    "    \"The bank branch is closed\",\n",
    "    \"He started working at the bank\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classify documents using the average of contextual word vectors\n",
    "**Try it yourself:** *Optional:* In previous sections we've built a classifier using the average of non-contextual word vectors. Now, try to use contextual word embeddings on our dataset. Use the average of these vectors and apply a classifier on it to obtain the predictions. Is the performance better than for non-contextual word vectors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embedding using ELMo\n",
    "We've used Flair to get embeddings for each word in the sentence. However, for text classification of the entire document, we need a way to integrate all these vectors into a single document embedding. There are several methods for that, and those interested would find this article useful - https://towardsdatascience.com/document-embedding-techniques-fed3e7a6a25d\n",
    "\n",
    "The most basic element is averaging the word embedding into a single document embedding. In FLAIR, we do this using a DocumentPooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocumentPoolEmbeddings(\n",
       "  fine_tune_mode=linear, pooling=mean\n",
       "  (embeddings): StackedEmbeddings(\n",
       "    (list_embedding_0): ELMoEmbeddings(model=elmo-original)\n",
       "  )\n",
       "  (embedding_flex): Linear(in_features=3072, out_features=3072, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.embeddings import DocumentPoolEmbeddings\n",
    "document_embeddings = DocumentPoolEmbeddings([elmo_embedding], pooling='mean')\n",
    "\n",
    "document_embeddings.embed(sentence)\n",
    "document_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072])\n",
      "tensor([-0.1185,  0.0253, -0.3043,  ..., -0.4902,  0.9246,  0.6966],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# now check out the embedded sentence.\n",
    "print(sentence.get_embedding().shape)\n",
    "print(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use an RNN that runs over the word embeddings. We will use the last hidden state as the document embedding. In this case it is very helpful to train the model using the true labels of our task, so that the RNN is optimized for our own data and task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, DocumentRNNEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "document_embeddings = DocumentRNNEmbeddings([glove_embedding], rnn_type='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.1027, -0.1833,  0.1588, -0.0189, -0.0200, -0.0450,  0.0138,  0.0329,\n",
      "        -0.1762,  0.0325,  0.2245, -0.0553, -0.0456, -0.0457,  0.3575,  0.0486,\n",
      "         0.3647, -0.0574, -0.1374, -0.0072,  0.1516, -0.0705, -0.1483, -0.0227,\n",
      "         0.0541, -0.0501, -0.0200, -0.3354,  0.1682,  0.0555, -0.2173, -0.0564,\n",
      "        -0.0606,  0.0550,  0.1950,  0.0486, -0.0994,  0.1542,  0.0731, -0.0298,\n",
      "         0.0631,  0.1804,  0.0638, -0.0166, -0.0665, -0.1210, -0.2998, -0.1263,\n",
      "        -0.2099, -0.1629,  0.2091, -0.1292,  0.1359, -0.0130,  0.1932,  0.0120,\n",
      "        -0.0294,  0.3837,  0.1122, -0.0678, -0.0818,  0.1508, -0.0017, -0.0788,\n",
      "         0.0623,  0.0702,  0.2679, -0.0483, -0.0035, -0.1998,  0.0654, -0.2028,\n",
      "        -0.1047,  0.1110,  0.1318, -0.2363,  0.0176, -0.0227,  0.0753,  0.0144,\n",
      "        -0.0770, -0.0076, -0.0836, -0.1628,  0.0625,  0.0755, -0.1855,  0.0374,\n",
      "         0.0665,  0.0162,  0.0702, -0.0649, -0.0161, -0.0772,  0.3199, -0.1396,\n",
      "         0.1110,  0.0626, -0.0382,  0.1907,  0.1822,  0.0696,  0.0628, -0.0128,\n",
      "         0.0840,  0.0316, -0.0243, -0.1160,  0.0997,  0.0120,  0.0314,  0.0819,\n",
      "        -0.0309,  0.0122, -0.0516,  0.1233,  0.0731, -0.0403,  0.1179, -0.1060,\n",
      "         0.1027,  0.0941, -0.1596, -0.0926, -0.1667,  0.0724,  0.1324,  0.1192],\n",
      "       grad_fn=<CatBackward>)\n"
     ]
    }
   ],
   "source": [
    "# create an example sentence\n",
    "sentence = Sentence('The grass is green . And the sky is blue .')\n",
    "\n",
    "# embed the sentence with our document embedding\n",
    "document_embeddings.embed(sentence)\n",
    "\n",
    "# now check out the embedded sentence.\n",
    "print(sentence.get_embedding())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that while `DocumentPoolEmbeddings` are immediately meaningful, `DocumentRNNEmbeddings` need to be tuned on the downstream task. This happens automatically in Flair if you train a new model with these embeddings. You can find an example of training a text classification model [here](/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md#training-a-text-classification-model). Once the model is trained, you can access the tuned DocumentRNNEmbeddings object directly from the classifier object and use it to embed sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DocumentRNNEmbeddings` have a number of hyper-parameters that can be tuned to improve learning:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    ":param hidden_size: the number of hidden states in the rnn.\n",
    ":param rnn_layers: the number of layers for the rnn.\n",
    ":param reproject_words: boolean value, indicating whether to reproject the token embeddings in a separate linear\n",
    "layer before putting them into the rnn or not.\n",
    ":param reproject_words_dimension: output dimension of reprojecting token embeddings. If None the same output\n",
    "dimension as before will be taken.\n",
    ":param bidirectional: boolean value, indicating whether to use a bidirectional rnn or not.\n",
    ":param dropout: the dropout value to be used.\n",
    ":param word_dropout: the word dropout value to be used, if 0.0 word dropout is not used.\n",
    ":param locked_dropout: the locked dropout value to be used, if 0.0 locked dropout is not used.\n",
    ":param rnn_type: one of 'RNN' or 'LSTM'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset\n",
    "The simplest way to load our data in Flair is using a CSV file. You can learn about other method in [the documentation](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_6_CORPUS.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a `Corpus` for a text classification task, you need to have three files (train, dev, and test) in the \n",
    "above format located in one folder. This data folder structure could, for example, look like this for the IMDB task:\n",
    "```text\n",
    "/data/train.csv\n",
    "/data/val.csv\n",
    "/data/test.txt\n",
    "```\n",
    "Now create a `CSVClassificationCorpus` by pointing to this folder (`/data`). \n",
    "Thereby, each line in a file is converted to a `Sentence` object annotated with the labels.\n",
    "\n",
    "Attention: A text in a line can in fact have multiple sentences. Thus, a `Sentence` object is actually a `Document` and can actually consist of multiple sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:39:43,110 Reading data from data\n",
      "2019-10-25 06:39:43,111 Train: data\\train.csv\n",
      "2019-10-25 06:39:43,112 Dev: data\\val.csv\n",
      "2019-10-25 06:39:43,112 Test: data\\test.csv\n",
      "2019-10-25 06:39:43,125 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 764/764 [00:00<00:00, 1152.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:39:58,081 [b'talk.politics.guns', b'rec.sport.baseball', b'rec.sport.hockey', b'talk.politics.mideast']\n"
     ]
    }
   ],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "\n",
    "# this is the folder in which train, test and dev files reside\n",
    "data_folder = 'data/'\n",
    "\n",
    "# column format indicating which columns hold the text and label(s). This is 1-based and not 0-based\n",
    "column_name_map = {5: \"text\", 4: \"label\"}\n",
    "\n",
    "# load corpus containing training, test and dev data\n",
    "corpus: Corpus = CSVClassificationCorpus(data_folder,\n",
    "                                         column_name_map,\n",
    "                                         skip_header=True,\n",
    "                                      test_file='test.csv',\n",
    "                                      dev_file='val.csv',\n",
    "                                      train_file='train.csv')\n",
    "    \n",
    "label_dict = corpus.make_label_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentence: \"check again . you may find that the arrest warrant was issued after the first firefight . --\" - 18 Tokens"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training our own model\n",
    "We're going to use an RNN to run through the contextual word embeddings we got from ELMo. We will use the hidden state at the end of the document as an embedding for the entire document. We will train the RNN on our labeled dataset, so that the final hidden state carries the most relevant information for our custom classification task.  \n",
    "\n",
    "For more information on training your own model using Flair, see [this tutorial](https://github.com/zalandoresearch/flair/blob/master/resources/docs/TUTORIAL_7_TRAINING_A_MODEL.md)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Change code below to fit our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Corpus\n",
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentRNNEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.trainers import ModelTrainer\n",
    "\n",
    "# 3. make a list of word embeddings\n",
    "word_embeddings = [WordEmbeddings('glove')]\n",
    "\n",
    "# 4. initialize document embedding by passing list of word embeddings\n",
    "# Can choose between many RNN types (GRU by default, to change use rnn_type parameter)\n",
    "document_embeddings: DocumentRNNEmbeddings = DocumentRNNEmbeddings(word_embeddings,\n",
    "                                                                     hidden_size=512,\n",
    "                                                                     reproject_words=True,\n",
    "                                                                     reproject_words_dimension=256,\n",
    "                                                                     )\n",
    "\n",
    "# 5. create the text classifier\n",
    "classifier = TextClassifier(document_embeddings, label_dictionary=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:40:32,949 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:32,950 Model: \"TextClassifier(\n",
      "  (document_embeddings): DocumentRNNEmbeddings(\n",
      "    (embeddings): StackedEmbeddings(\n",
      "      (list_embedding_0): WordEmbeddings('glove')\n",
      "    )\n",
      "    (word_reprojection_map): Linear(in_features=100, out_features=256, bias=True)\n",
      "    (rnn): GRU(256, 512)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "  )\n",
      "  (decoder): Linear(in_features=512, out_features=4, bias=True)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      ")\"\n",
      "2019-10-25 06:40:32,951 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:32,952 Corpus: \"Corpus: 764 train + 164 dev + 164 test sentences\"\n",
      "2019-10-25 06:40:32,953 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:32,954 Parameters:\n",
      "2019-10-25 06:40:32,955  - learning_rate: \"0.1\"\n",
      "2019-10-25 06:40:32,956  - mini_batch_size: \"32\"\n",
      "2019-10-25 06:40:32,956  - patience: \"5\"\n",
      "2019-10-25 06:40:32,957  - anneal_factor: \"0.5\"\n",
      "2019-10-25 06:40:32,958  - max_epochs: \"150\"\n",
      "2019-10-25 06:40:32,959  - shuffle: \"True\"\n",
      "2019-10-25 06:40:32,960  - train_with_dev: \"False\"\n",
      "2019-10-25 06:40:32,961 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:32,962 Model training base path: \"data\"\n",
      "2019-10-25 06:40:32,963 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:32,963 Device: cpu\n",
      "2019-10-25 06:40:32,964 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:32,965 Embeddings storage mode: cpu\n",
      "2019-10-25 06:40:32,967 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:40:44,349 epoch 1 - iter 0/24 - loss 1.49370718 - samples/sec: 87.02\n",
      "2019-10-25 06:40:45,895 epoch 1 - iter 2/24 - loss 1.66083467 - samples/sec: 42.77\n",
      "2019-10-25 06:40:47,505 epoch 1 - iter 4/24 - loss 1.57539825 - samples/sec: 40.93\n",
      "2019-10-25 06:40:48,974 epoch 1 - iter 6/24 - loss 1.52626928 - samples/sec: 44.97\n",
      "2019-10-25 06:40:50,463 epoch 1 - iter 8/24 - loss 1.52883701 - samples/sec: 44.50\n",
      "2019-10-25 06:40:51,812 epoch 1 - iter 10/24 - loss 1.50611903 - samples/sec: 48.93\n",
      "2019-10-25 06:40:53,449 epoch 1 - iter 12/24 - loss 1.48764301 - samples/sec: 41.37\n",
      "2019-10-25 06:40:55,190 epoch 1 - iter 14/24 - loss 1.48706020 - samples/sec: 37.96\n",
      "2019-10-25 06:40:57,000 epoch 1 - iter 16/24 - loss 1.47729754 - samples/sec: 36.46\n",
      "2019-10-25 06:40:58,726 epoch 1 - iter 18/24 - loss 1.46302881 - samples/sec: 38.27\n",
      "2019-10-25 06:41:00,594 epoch 1 - iter 20/24 - loss 1.45581440 - samples/sec: 35.39\n",
      "2019-10-25 06:41:02,386 epoch 1 - iter 22/24 - loss 1.45660043 - samples/sec: 36.70\n",
      "2019-10-25 06:41:03,551 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:41:03,553 EPOCH 1 done: loss 1.4516 - lr 0.1000\n",
      "2019-10-25 06:41:14,998 DEV : loss 1.3400391340255737 - score 0.2744\n",
      "2019-10-25 06:41:15,114 BAD EPOCHS (no improvement): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type DocumentRNNEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type StackedEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type WordEmbeddings. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Linear. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type GRU. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\serialization.py:292: UserWarning: Couldn't retrieve source code for container of type Dropout. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:41:18,046 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:41:29,540 epoch 2 - iter 0/24 - loss 1.38134038 - samples/sec: 89.03\n",
      "2019-10-25 06:41:31,434 epoch 2 - iter 2/24 - loss 1.27515229 - samples/sec: 34.80\n",
      "2019-10-25 06:41:33,158 epoch 2 - iter 4/24 - loss 1.24434588 - samples/sec: 38.15\n",
      "2019-10-25 06:41:35,326 epoch 2 - iter 6/24 - loss 1.28255429 - samples/sec: 30.41\n",
      "2019-10-25 06:41:37,470 epoch 2 - iter 8/24 - loss 1.29598440 - samples/sec: 30.82\n",
      "2019-10-25 06:41:39,173 epoch 2 - iter 10/24 - loss 1.31206984 - samples/sec: 39.19\n",
      "2019-10-25 06:41:40,820 epoch 2 - iter 12/24 - loss 1.30308888 - samples/sec: 40.35\n",
      "2019-10-25 06:41:43,195 epoch 2 - iter 14/24 - loss 1.30053051 - samples/sec: 33.11\n",
      "2019-10-25 06:41:45,092 epoch 2 - iter 16/24 - loss 1.29916115 - samples/sec: 34.79\n",
      "2019-10-25 06:41:47,098 epoch 2 - iter 18/24 - loss 1.29539271 - samples/sec: 32.96\n",
      "2019-10-25 06:41:48,824 epoch 2 - iter 20/24 - loss 1.29464445 - samples/sec: 38.32\n",
      "2019-10-25 06:41:50,599 epoch 2 - iter 22/24 - loss 1.29447735 - samples/sec: 37.17\n",
      "2019-10-25 06:41:52,076 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:41:52,077 EPOCH 2 done: loss 1.2946 - lr 0.1000\n",
      "2019-10-25 06:42:05,811 DEV : loss 1.3258041143417358 - score 0.3293\n",
      "2019-10-25 06:42:05,939 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:42:08,756 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:42:20,625 epoch 3 - iter 0/24 - loss 1.46180856 - samples/sec: 74.88\n",
      "2019-10-25 06:42:22,620 epoch 3 - iter 2/24 - loss 1.29437613 - samples/sec: 33.08\n",
      "2019-10-25 06:42:24,567 epoch 3 - iter 4/24 - loss 1.23508685 - samples/sec: 33.55\n",
      "2019-10-25 06:42:26,447 epoch 3 - iter 6/24 - loss 1.23336143 - samples/sec: 35.26\n",
      "2019-10-25 06:42:28,071 epoch 3 - iter 8/24 - loss 1.25866107 - samples/sec: 40.89\n",
      "2019-10-25 06:42:29,820 epoch 3 - iter 10/24 - loss 1.28187623 - samples/sec: 37.45\n",
      "2019-10-25 06:42:31,653 epoch 3 - iter 12/24 - loss 1.27474672 - samples/sec: 36.10\n",
      "2019-10-25 06:42:33,425 epoch 3 - iter 14/24 - loss 1.27405032 - samples/sec: 37.37\n",
      "2019-10-25 06:42:35,250 epoch 3 - iter 16/24 - loss 1.27495852 - samples/sec: 35.97\n",
      "2019-10-25 06:42:37,193 epoch 3 - iter 18/24 - loss 1.27672600 - samples/sec: 34.17\n",
      "2019-10-25 06:42:39,047 epoch 3 - iter 20/24 - loss 1.27977267 - samples/sec: 35.60\n",
      "2019-10-25 06:42:40,726 epoch 3 - iter 22/24 - loss 1.27488453 - samples/sec: 39.14\n",
      "2019-10-25 06:42:41,703 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:42:41,705 EPOCH 3 done: loss 1.2706 - lr 0.1000\n",
      "2019-10-25 06:42:54,407 DEV : loss 1.2319387197494507 - score 0.3963\n",
      "2019-10-25 06:42:54,536 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:42:57,483 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:43:09,139 epoch 4 - iter 0/24 - loss 1.24534404 - samples/sec: 79.82\n",
      "2019-10-25 06:43:10,704 epoch 4 - iter 2/24 - loss 1.28002946 - samples/sec: 41.98\n",
      "2019-10-25 06:43:12,315 epoch 4 - iter 4/24 - loss 1.20169058 - samples/sec: 40.97\n",
      "2019-10-25 06:43:14,026 epoch 4 - iter 6/24 - loss 1.21453953 - samples/sec: 38.82\n",
      "2019-10-25 06:43:16,001 epoch 4 - iter 8/24 - loss 1.23723184 - samples/sec: 33.32\n",
      "2019-10-25 06:43:17,761 epoch 4 - iter 10/24 - loss 1.24058857 - samples/sec: 37.47\n",
      "2019-10-25 06:43:19,718 epoch 4 - iter 12/24 - loss 1.23876667 - samples/sec: 43.94\n",
      "2019-10-25 06:43:21,561 epoch 4 - iter 14/24 - loss 1.22932731 - samples/sec: 35.68\n",
      "2019-10-25 06:43:23,397 epoch 4 - iter 16/24 - loss 1.22822231 - samples/sec: 35.77\n",
      "2019-10-25 06:43:25,433 epoch 4 - iter 18/24 - loss 1.22904843 - samples/sec: 32.59\n",
      "2019-10-25 06:43:27,281 epoch 4 - iter 20/24 - loss 1.23261417 - samples/sec: 35.67\n",
      "2019-10-25 06:43:29,209 epoch 4 - iter 22/24 - loss 1.22847642 - samples/sec: 34.06\n",
      "2019-10-25 06:43:30,593 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:43:30,595 EPOCH 4 done: loss 1.2284 - lr 0.1000\n",
      "2019-10-25 06:43:52,040 DEV : loss 1.2219551801681519 - score 0.3841\n",
      "2019-10-25 06:43:52,213 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 06:43:52,216 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:44:06,991 epoch 5 - iter 0/24 - loss 1.02426541 - samples/sec: 72.43\n",
      "2019-10-25 06:44:08,961 epoch 5 - iter 2/24 - loss 1.12774396 - samples/sec: 33.69\n",
      "2019-10-25 06:44:11,018 epoch 5 - iter 4/24 - loss 1.17516201 - samples/sec: 31.77\n",
      "2019-10-25 06:44:13,176 epoch 5 - iter 6/24 - loss 1.19186359 - samples/sec: 30.50\n",
      "2019-10-25 06:44:15,239 epoch 5 - iter 8/24 - loss 1.19857278 - samples/sec: 32.14\n",
      "2019-10-25 06:44:17,338 epoch 5 - iter 10/24 - loss 1.17900890 - samples/sec: 31.19\n",
      "2019-10-25 06:44:19,044 epoch 5 - iter 12/24 - loss 1.19842371 - samples/sec: 38.82\n",
      "2019-10-25 06:44:20,971 epoch 5 - iter 14/24 - loss 1.19124865 - samples/sec: 34.38\n",
      "2019-10-25 06:44:22,761 epoch 5 - iter 16/24 - loss 1.19321835 - samples/sec: 37.67\n",
      "2019-10-25 06:44:24,744 epoch 5 - iter 18/24 - loss 1.17937747 - samples/sec: 33.18\n",
      "2019-10-25 06:44:26,633 epoch 5 - iter 20/24 - loss 1.17501188 - samples/sec: 35.10\n",
      "2019-10-25 06:44:28,461 epoch 5 - iter 22/24 - loss 1.17509473 - samples/sec: 35.86\n",
      "2019-10-25 06:44:29,524 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:44:29,526 EPOCH 5 done: loss 1.1777 - lr 0.1000\n",
      "2019-10-25 06:44:44,252 DEV : loss 1.2259411811828613 - score 0.3841\n",
      "2019-10-25 06:44:44,377 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 06:44:44,379 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:45:01,237 epoch 6 - iter 0/24 - loss 1.02712762 - samples/sec: 67.16\n",
      "2019-10-25 06:45:02,957 epoch 6 - iter 2/24 - loss 1.13114409 - samples/sec: 38.51\n",
      "2019-10-25 06:45:04,674 epoch 6 - iter 4/24 - loss 1.12224784 - samples/sec: 38.34\n",
      "2019-10-25 06:45:06,507 epoch 6 - iter 6/24 - loss 1.15079357 - samples/sec: 36.17\n",
      "2019-10-25 06:45:08,455 epoch 6 - iter 8/24 - loss 1.16654707 - samples/sec: 33.79\n",
      "2019-10-25 06:45:10,618 epoch 6 - iter 10/24 - loss 1.19052150 - samples/sec: 30.25\n",
      "2019-10-25 06:45:12,178 epoch 6 - iter 12/24 - loss 1.19376979 - samples/sec: 42.52\n",
      "2019-10-25 06:45:14,081 epoch 6 - iter 14/24 - loss 1.18260033 - samples/sec: 34.68\n",
      "2019-10-25 06:45:16,115 epoch 6 - iter 16/24 - loss 1.17225082 - samples/sec: 32.28\n",
      "2019-10-25 06:45:17,947 epoch 6 - iter 18/24 - loss 1.16228885 - samples/sec: 36.36\n",
      "2019-10-25 06:45:19,641 epoch 6 - iter 20/24 - loss 1.15199870 - samples/sec: 39.04\n",
      "2019-10-25 06:45:21,489 epoch 6 - iter 22/24 - loss 1.14879642 - samples/sec: 35.50\n",
      "2019-10-25 06:45:22,553 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:45:22,554 EPOCH 6 done: loss 1.1540 - lr 0.1000\n",
      "2019-10-25 06:45:34,150 DEV : loss 1.3024336099624634 - score 0.372\n",
      "2019-10-25 06:45:34,277 BAD EPOCHS (no improvement): 3\n",
      "2019-10-25 06:45:34,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:45:45,937 epoch 7 - iter 0/24 - loss 1.26932406 - samples/sec: 67.11\n",
      "2019-10-25 06:45:47,643 epoch 7 - iter 2/24 - loss 1.25166504 - samples/sec: 38.84\n",
      "2019-10-25 06:45:49,425 epoch 7 - iter 4/24 - loss 1.25595636 - samples/sec: 37.00\n",
      "2019-10-25 06:45:51,269 epoch 7 - iter 6/24 - loss 1.29176666 - samples/sec: 35.99\n",
      "2019-10-25 06:45:53,159 epoch 7 - iter 8/24 - loss 1.33106335 - samples/sec: 34.77\n",
      "2019-10-25 06:45:54,822 epoch 7 - iter 10/24 - loss 1.30735317 - samples/sec: 39.71\n",
      "2019-10-25 06:45:56,624 epoch 7 - iter 12/24 - loss 1.26918506 - samples/sec: 36.89\n",
      "2019-10-25 06:45:58,213 epoch 7 - iter 14/24 - loss 1.25075198 - samples/sec: 41.41\n",
      "2019-10-25 06:45:59,914 epoch 7 - iter 16/24 - loss 1.23510830 - samples/sec: 38.76\n",
      "2019-10-25 06:46:01,997 epoch 7 - iter 18/24 - loss 1.22254636 - samples/sec: 31.78\n",
      "2019-10-25 06:46:03,638 epoch 7 - iter 20/24 - loss 1.20409148 - samples/sec: 40.18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:46:05,578 epoch 7 - iter 22/24 - loss 1.19991632 - samples/sec: 33.96\n",
      "2019-10-25 06:46:06,903 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:46:06,905 EPOCH 7 done: loss 1.1955 - lr 0.1000\n",
      "2019-10-25 06:46:18,289 DEV : loss 1.2214267253875732 - score 0.3537\n",
      "2019-10-25 06:46:18,397 BAD EPOCHS (no improvement): 4\n",
      "2019-10-25 06:46:18,400 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:46:32,221 epoch 8 - iter 0/24 - loss 1.11569440 - samples/sec: 86.55\n",
      "2019-10-25 06:46:33,998 epoch 8 - iter 2/24 - loss 1.07375638 - samples/sec: 37.03\n",
      "2019-10-25 06:46:35,886 epoch 8 - iter 4/24 - loss 1.16339598 - samples/sec: 34.99\n",
      "2019-10-25 06:46:37,751 epoch 8 - iter 6/24 - loss 1.19701326 - samples/sec: 35.62\n",
      "2019-10-25 06:46:39,480 epoch 8 - iter 8/24 - loss 1.17006695 - samples/sec: 38.20\n",
      "2019-10-25 06:46:41,424 epoch 8 - iter 10/24 - loss 1.15266242 - samples/sec: 33.78\n",
      "2019-10-25 06:46:43,604 epoch 8 - iter 12/24 - loss 1.16087550 - samples/sec: 38.56\n",
      "2019-10-25 06:46:45,400 epoch 8 - iter 14/24 - loss 1.16384623 - samples/sec: 36.76\n",
      "2019-10-25 06:46:47,341 epoch 8 - iter 16/24 - loss 1.16130214 - samples/sec: 34.33\n",
      "2019-10-25 06:46:49,071 epoch 8 - iter 18/24 - loss 1.14735534 - samples/sec: 38.32\n",
      "2019-10-25 06:46:50,984 epoch 8 - iter 20/24 - loss 1.14257476 - samples/sec: 34.41\n",
      "2019-10-25 06:46:52,764 epoch 8 - iter 22/24 - loss 1.14323298 - samples/sec: 36.98\n",
      "2019-10-25 06:46:53,863 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:46:53,865 EPOCH 8 done: loss 1.1492 - lr 0.1000\n",
      "2019-10-25 06:47:05,614 DEV : loss 1.2085317373275757 - score 0.4268\n",
      "2019-10-25 06:47:05,727 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:47:08,537 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:47:20,110 epoch 9 - iter 0/24 - loss 0.97680891 - samples/sec: 74.93\n",
      "2019-10-25 06:47:21,823 epoch 9 - iter 2/24 - loss 1.00169255 - samples/sec: 38.60\n",
      "2019-10-25 06:47:23,681 epoch 9 - iter 4/24 - loss 1.08606230 - samples/sec: 35.36\n",
      "2019-10-25 06:47:25,858 epoch 9 - iter 6/24 - loss 1.11664546 - samples/sec: 30.37\n",
      "2019-10-25 06:47:27,840 epoch 9 - iter 8/24 - loss 1.08694990 - samples/sec: 33.45\n",
      "2019-10-25 06:47:29,509 epoch 9 - iter 10/24 - loss 1.09188288 - samples/sec: 39.56\n",
      "2019-10-25 06:47:31,356 epoch 9 - iter 12/24 - loss 1.09346728 - samples/sec: 35.84\n",
      "2019-10-25 06:47:33,263 epoch 9 - iter 14/24 - loss 1.11769158 - samples/sec: 34.50\n",
      "2019-10-25 06:47:35,267 epoch 9 - iter 16/24 - loss 1.16920258 - samples/sec: 32.78\n",
      "2019-10-25 06:47:37,274 epoch 9 - iter 18/24 - loss 1.15600981 - samples/sec: 32.98\n",
      "2019-10-25 06:47:39,217 epoch 9 - iter 20/24 - loss 1.14515976 - samples/sec: 33.95\n",
      "2019-10-25 06:47:41,240 epoch 9 - iter 22/24 - loss 1.15424331 - samples/sec: 32.46\n",
      "2019-10-25 06:47:43,078 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:47:43,080 EPOCH 9 done: loss 1.1557 - lr 0.1000\n",
      "2019-10-25 06:47:56,704 DEV : loss 1.205046534538269 - score 0.3963\n",
      "2019-10-25 06:47:56,826 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 06:47:56,828 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:48:09,661 epoch 10 - iter 0/24 - loss 1.12677407 - samples/sec: 79.96\n",
      "2019-10-25 06:48:11,624 epoch 10 - iter 2/24 - loss 1.03232638 - samples/sec: 33.78\n",
      "2019-10-25 06:48:13,376 epoch 10 - iter 4/24 - loss 1.07426832 - samples/sec: 37.51\n",
      "2019-10-25 06:48:15,031 epoch 10 - iter 6/24 - loss 1.08873587 - samples/sec: 40.25\n",
      "2019-10-25 06:48:16,944 epoch 10 - iter 8/24 - loss 1.09692098 - samples/sec: 34.65\n",
      "2019-10-25 06:48:18,654 epoch 10 - iter 10/24 - loss 1.09070301 - samples/sec: 38.35\n",
      "2019-10-25 06:48:20,741 epoch 10 - iter 12/24 - loss 1.07562200 - samples/sec: 40.18\n",
      "2019-10-25 06:48:22,601 epoch 10 - iter 14/24 - loss 1.06614679 - samples/sec: 35.57\n",
      "2019-10-25 06:48:24,296 epoch 10 - iter 16/24 - loss 1.07104227 - samples/sec: 38.72\n",
      "2019-10-25 06:48:26,266 epoch 10 - iter 18/24 - loss 1.08764726 - samples/sec: 33.56\n",
      "2019-10-25 06:48:28,117 epoch 10 - iter 20/24 - loss 1.08230280 - samples/sec: 35.86\n",
      "2019-10-25 06:48:29,816 epoch 10 - iter 22/24 - loss 1.07468453 - samples/sec: 38.67\n",
      "2019-10-25 06:48:30,867 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:48:30,868 EPOCH 10 done: loss 1.0638 - lr 0.1000\n",
      "2019-10-25 06:48:42,311 DEV : loss 1.1346577405929565 - score 0.4207\n",
      "2019-10-25 06:48:42,432 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 06:48:42,434 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:48:53,952 epoch 11 - iter 0/24 - loss 1.01405311 - samples/sec: 75.85\n",
      "2019-10-25 06:48:55,712 epoch 11 - iter 2/24 - loss 0.96888596 - samples/sec: 37.58\n",
      "2019-10-25 06:48:57,467 epoch 11 - iter 4/24 - loss 0.97660027 - samples/sec: 37.78\n",
      "2019-10-25 06:48:59,190 epoch 11 - iter 6/24 - loss 1.06559675 - samples/sec: 38.74\n",
      "2019-10-25 06:49:00,856 epoch 11 - iter 8/24 - loss 1.07065632 - samples/sec: 39.62\n",
      "2019-10-25 06:49:02,700 epoch 11 - iter 10/24 - loss 1.06973840 - samples/sec: 35.71\n",
      "2019-10-25 06:49:04,644 epoch 11 - iter 12/24 - loss 1.06038025 - samples/sec: 34.25\n",
      "2019-10-25 06:49:06,377 epoch 11 - iter 14/24 - loss 1.07752624 - samples/sec: 38.02\n",
      "2019-10-25 06:49:08,208 epoch 11 - iter 16/24 - loss 1.07876001 - samples/sec: 35.95\n",
      "2019-10-25 06:49:10,062 epoch 11 - iter 18/24 - loss 1.08786936 - samples/sec: 36.07\n",
      "2019-10-25 06:49:11,813 epoch 11 - iter 20/24 - loss 1.09268912 - samples/sec: 37.64\n",
      "2019-10-25 06:49:13,772 epoch 11 - iter 22/24 - loss 1.08822932 - samples/sec: 33.62\n",
      "2019-10-25 06:49:15,053 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:49:15,054 EPOCH 11 done: loss 1.0891 - lr 0.1000\n",
      "2019-10-25 06:49:26,707 DEV : loss 1.1110105514526367 - score 0.4695\n",
      "2019-10-25 06:49:26,827 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:49:29,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:49:41,256 epoch 12 - iter 0/24 - loss 1.04942822 - samples/sec: 62.24\n",
      "2019-10-25 06:49:42,953 epoch 12 - iter 2/24 - loss 1.28411837 - samples/sec: 39.02\n",
      "2019-10-25 06:49:44,754 epoch 12 - iter 4/24 - loss 1.19519532 - samples/sec: 36.50\n",
      "2019-10-25 06:49:46,722 epoch 12 - iter 6/24 - loss 1.14635070 - samples/sec: 33.76\n",
      "2019-10-25 06:49:48,712 epoch 12 - iter 8/24 - loss 1.09940680 - samples/sec: 33.15\n",
      "2019-10-25 06:49:50,575 epoch 12 - iter 10/24 - loss 1.11606169 - samples/sec: 35.20\n",
      "2019-10-25 06:49:52,900 epoch 12 - iter 12/24 - loss 1.13330933 - samples/sec: 35.17\n",
      "2019-10-25 06:49:54,849 epoch 12 - iter 14/24 - loss 1.13795190 - samples/sec: 33.89\n",
      "2019-10-25 06:49:57,159 epoch 12 - iter 16/24 - loss 1.12340417 - samples/sec: 28.36\n",
      "2019-10-25 06:49:59,074 epoch 12 - iter 18/24 - loss 1.09578918 - samples/sec: 34.73\n",
      "2019-10-25 06:50:00,990 epoch 12 - iter 20/24 - loss 1.09357917 - samples/sec: 34.45\n",
      "2019-10-25 06:50:02,930 epoch 12 - iter 22/24 - loss 1.08048112 - samples/sec: 33.77\n",
      "2019-10-25 06:50:04,355 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:50:04,357 EPOCH 12 done: loss 1.0887 - lr 0.1000\n",
      "2019-10-25 06:50:17,028 DEV : loss 1.6641587018966675 - score 0.3232\n",
      "2019-10-25 06:50:17,144 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 06:50:17,147 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:50:30,681 epoch 13 - iter 0/24 - loss 1.24824691 - samples/sec: 75.84\n",
      "2019-10-25 06:50:32,437 epoch 13 - iter 2/24 - loss 1.02547894 - samples/sec: 37.61\n",
      "2019-10-25 06:50:34,363 epoch 13 - iter 4/24 - loss 1.06379851 - samples/sec: 34.19\n",
      "2019-10-25 06:50:36,353 epoch 13 - iter 6/24 - loss 1.17907603 - samples/sec: 33.24\n",
      "2019-10-25 06:50:38,103 epoch 13 - iter 8/24 - loss 1.16979400 - samples/sec: 37.73\n",
      "2019-10-25 06:50:40,115 epoch 13 - iter 10/24 - loss 1.13031681 - samples/sec: 32.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:50:41,806 epoch 13 - iter 12/24 - loss 1.12940287 - samples/sec: 39.31\n",
      "2019-10-25 06:50:43,675 epoch 13 - iter 14/24 - loss 1.11932804 - samples/sec: 35.45\n",
      "2019-10-25 06:50:45,730 epoch 13 - iter 16/24 - loss 1.09389845 - samples/sec: 32.01\n",
      "2019-10-25 06:50:47,497 epoch 13 - iter 18/24 - loss 1.11355928 - samples/sec: 37.72\n",
      "2019-10-25 06:50:49,364 epoch 13 - iter 20/24 - loss 1.10975074 - samples/sec: 35.31\n",
      "2019-10-25 06:50:50,897 epoch 13 - iter 22/24 - loss 1.10141043 - samples/sec: 43.20\n",
      "2019-10-25 06:50:52,133 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:50:52,135 EPOCH 13 done: loss 1.0914 - lr 0.1000\n",
      "2019-10-25 06:51:04,001 DEV : loss 1.09210205078125 - score 0.4634\n",
      "2019-10-25 06:51:04,148 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 06:51:04,151 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:51:15,745 epoch 14 - iter 0/24 - loss 0.95133621 - samples/sec: 74.26\n",
      "2019-10-25 06:51:17,730 epoch 14 - iter 2/24 - loss 1.03494455 - samples/sec: 33.55\n",
      "2019-10-25 06:51:19,608 epoch 14 - iter 4/24 - loss 1.01336411 - samples/sec: 34.85\n",
      "2019-10-25 06:51:21,391 epoch 14 - iter 6/24 - loss 1.03098469 - samples/sec: 37.12\n",
      "2019-10-25 06:51:23,300 epoch 14 - iter 8/24 - loss 1.01042110 - samples/sec: 45.95\n",
      "2019-10-25 06:51:24,984 epoch 14 - iter 10/24 - loss 1.03942414 - samples/sec: 39.20\n",
      "2019-10-25 06:51:26,974 epoch 14 - iter 12/24 - loss 1.03367804 - samples/sec: 33.21\n",
      "2019-10-25 06:51:28,720 epoch 14 - iter 14/24 - loss 1.02960951 - samples/sec: 38.18\n",
      "2019-10-25 06:51:30,457 epoch 14 - iter 16/24 - loss 1.00565918 - samples/sec: 37.77\n",
      "2019-10-25 06:51:32,514 epoch 14 - iter 18/24 - loss 0.99856470 - samples/sec: 32.06\n",
      "2019-10-25 06:51:34,496 epoch 14 - iter 20/24 - loss 1.04650198 - samples/sec: 33.63\n",
      "2019-10-25 06:51:36,392 epoch 14 - iter 22/24 - loss 1.06044321 - samples/sec: 34.59\n",
      "2019-10-25 06:51:37,535 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:51:37,536 EPOCH 14 done: loss 1.0574 - lr 0.1000\n",
      "2019-10-25 06:51:49,364 DEV : loss 1.1276899576187134 - score 0.4268\n",
      "2019-10-25 06:51:49,481 BAD EPOCHS (no improvement): 3\n",
      "2019-10-25 06:51:49,483 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:52:01,208 epoch 15 - iter 0/24 - loss 1.10257423 - samples/sec: 75.09\n",
      "2019-10-25 06:52:02,994 epoch 15 - iter 2/24 - loss 1.01039465 - samples/sec: 37.24\n",
      "2019-10-25 06:52:05,038 epoch 15 - iter 4/24 - loss 1.10274532 - samples/sec: 32.27\n",
      "2019-10-25 06:52:07,141 epoch 15 - iter 6/24 - loss 1.11076943 - samples/sec: 31.36\n",
      "2019-10-25 06:52:08,833 epoch 15 - iter 8/24 - loss 1.14506972 - samples/sec: 39.50\n",
      "2019-10-25 06:52:10,473 epoch 15 - iter 10/24 - loss 1.13533274 - samples/sec: 40.23\n",
      "2019-10-25 06:52:12,554 epoch 15 - iter 12/24 - loss 1.13149395 - samples/sec: 31.69\n",
      "2019-10-25 06:52:14,700 epoch 15 - iter 14/24 - loss 1.10887751 - samples/sec: 30.94\n",
      "2019-10-25 06:52:16,784 epoch 15 - iter 16/24 - loss 1.09835422 - samples/sec: 31.48\n",
      "2019-10-25 06:52:18,585 epoch 15 - iter 18/24 - loss 1.09574739 - samples/sec: 36.69\n",
      "2019-10-25 06:52:20,420 epoch 15 - iter 20/24 - loss 1.09254673 - samples/sec: 36.29\n",
      "2019-10-25 06:52:22,563 epoch 15 - iter 22/24 - loss 1.07697245 - samples/sec: 30.62\n",
      "2019-10-25 06:52:23,836 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:52:23,838 EPOCH 15 done: loss 1.0713 - lr 0.1000\n",
      "2019-10-25 06:52:37,030 DEV : loss 1.1526893377304077 - score 0.4207\n",
      "2019-10-25 06:52:37,147 BAD EPOCHS (no improvement): 4\n",
      "2019-10-25 06:52:37,149 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:52:48,861 epoch 16 - iter 0/24 - loss 1.11410451 - samples/sec: 74.98\n",
      "2019-10-25 06:52:50,618 epoch 16 - iter 2/24 - loss 1.25499201 - samples/sec: 38.00\n",
      "2019-10-25 06:52:52,691 epoch 16 - iter 4/24 - loss 1.22780826 - samples/sec: 31.60\n",
      "2019-10-25 06:52:54,981 epoch 16 - iter 6/24 - loss 1.15970030 - samples/sec: 35.72\n",
      "2019-10-25 06:52:57,173 epoch 16 - iter 8/24 - loss 1.09698311 - samples/sec: 30.23\n",
      "2019-10-25 06:52:59,002 epoch 16 - iter 10/24 - loss 1.10728258 - samples/sec: 35.95\n",
      "2019-10-25 06:53:00,846 epoch 16 - iter 12/24 - loss 1.11332107 - samples/sec: 35.96\n",
      "2019-10-25 06:53:02,543 epoch 16 - iter 14/24 - loss 1.07346392 - samples/sec: 39.28\n",
      "2019-10-25 06:53:04,253 epoch 16 - iter 16/24 - loss 1.07230932 - samples/sec: 38.38\n",
      "2019-10-25 06:53:06,295 epoch 16 - iter 18/24 - loss 1.06659432 - samples/sec: 32.34\n",
      "2019-10-25 06:53:08,357 epoch 16 - iter 20/24 - loss 1.05012009 - samples/sec: 32.07\n",
      "2019-10-25 06:53:10,193 epoch 16 - iter 22/24 - loss 1.03343324 - samples/sec: 35.76\n",
      "2019-10-25 06:53:11,279 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:53:11,281 EPOCH 16 done: loss 1.0301 - lr 0.1000\n",
      "2019-10-25 06:53:23,901 DEV : loss 1.284629464149475 - score 0.4268\n",
      "2019-10-25 06:53:24,076 BAD EPOCHS (no improvement): 5\n",
      "2019-10-25 06:53:24,080 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:53:41,570 epoch 17 - iter 0/24 - loss 1.06840241 - samples/sec: 64.79\n",
      "2019-10-25 06:53:43,569 epoch 17 - iter 2/24 - loss 0.98239706 - samples/sec: 32.87\n",
      "2019-10-25 06:53:45,458 epoch 17 - iter 4/24 - loss 1.06116561 - samples/sec: 35.16\n",
      "2019-10-25 06:53:47,304 epoch 17 - iter 6/24 - loss 1.01720010 - samples/sec: 36.19\n",
      "2019-10-25 06:53:49,149 epoch 17 - iter 8/24 - loss 1.02363791 - samples/sec: 35.50\n",
      "2019-10-25 06:53:50,939 epoch 17 - iter 10/24 - loss 1.01624986 - samples/sec: 36.79\n",
      "2019-10-25 06:53:53,059 epoch 17 - iter 12/24 - loss 1.03513672 - samples/sec: 31.62\n",
      "2019-10-25 06:53:55,461 epoch 17 - iter 14/24 - loss 1.02758862 - samples/sec: 27.24\n",
      "2019-10-25 06:53:57,830 epoch 17 - iter 16/24 - loss 1.01641542 - samples/sec: 28.01\n",
      "2019-10-25 06:53:59,991 epoch 17 - iter 18/24 - loss 1.03014523 - samples/sec: 30.79\n",
      "2019-10-25 06:54:02,397 epoch 17 - iter 20/24 - loss 1.07086249 - samples/sec: 27.49\n",
      "2019-10-25 06:54:04,576 epoch 17 - iter 22/24 - loss 1.06399003 - samples/sec: 30.74\n",
      "2019-10-25 06:54:05,966 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:54:05,967 EPOCH 17 done: loss 1.0523 - lr 0.1000\n",
      "2019-10-25 06:54:18,946 DEV : loss 1.1689001321792603 - score 0.4024\n",
      "Epoch    16: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-10-25 06:54:19,066 BAD EPOCHS (no improvement): 6\n",
      "2019-10-25 06:54:19,067 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:54:31,278 epoch 18 - iter 0/24 - loss 1.23802722 - samples/sec: 73.68\n",
      "2019-10-25 06:54:33,764 epoch 18 - iter 2/24 - loss 0.99508784 - samples/sec: 33.35\n",
      "2019-10-25 06:54:35,342 epoch 18 - iter 4/24 - loss 0.96726166 - samples/sec: 41.84\n",
      "2019-10-25 06:54:37,221 epoch 18 - iter 6/24 - loss 0.94434512 - samples/sec: 35.28\n",
      "2019-10-25 06:54:38,915 epoch 18 - iter 8/24 - loss 0.91106891 - samples/sec: 39.14\n",
      "2019-10-25 06:54:40,499 epoch 18 - iter 10/24 - loss 0.93460463 - samples/sec: 41.54\n",
      "2019-10-25 06:54:42,345 epoch 18 - iter 12/24 - loss 0.93072789 - samples/sec: 35.88\n",
      "2019-10-25 06:54:44,451 epoch 18 - iter 14/24 - loss 0.91978918 - samples/sec: 31.32\n",
      "2019-10-25 06:54:46,438 epoch 18 - iter 16/24 - loss 0.93873265 - samples/sec: 32.93\n",
      "2019-10-25 06:54:48,279 epoch 18 - iter 18/24 - loss 0.94310575 - samples/sec: 36.00\n",
      "2019-10-25 06:54:50,097 epoch 18 - iter 20/24 - loss 0.92877232 - samples/sec: 36.43\n",
      "2019-10-25 06:54:51,964 epoch 18 - iter 22/24 - loss 0.92770787 - samples/sec: 35.08\n",
      "2019-10-25 06:54:53,246 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:54:53,248 EPOCH 18 done: loss 0.9246 - lr 0.0500\n",
      "2019-10-25 06:55:05,637 DEV : loss 1.0092501640319824 - score 0.4817\n",
      "2019-10-25 06:55:05,803 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:55:08,830 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 06:55:21,052 epoch 19 - iter 0/24 - loss 0.86436689 - samples/sec: 71.56\n",
      "2019-10-25 06:55:22,854 epoch 19 - iter 2/24 - loss 0.82941147 - samples/sec: 37.04\n",
      "2019-10-25 06:55:25,303 epoch 19 - iter 4/24 - loss 0.87983798 - samples/sec: 26.72\n",
      "2019-10-25 06:55:27,475 epoch 19 - iter 6/24 - loss 0.90989699 - samples/sec: 30.51\n",
      "2019-10-25 06:55:29,220 epoch 19 - iter 8/24 - loss 0.86983003 - samples/sec: 38.01\n",
      "2019-10-25 06:55:30,989 epoch 19 - iter 10/24 - loss 0.85046833 - samples/sec: 37.23\n",
      "2019-10-25 06:55:32,795 epoch 19 - iter 12/24 - loss 0.86228786 - samples/sec: 36.53\n",
      "2019-10-25 06:55:34,756 epoch 19 - iter 14/24 - loss 0.86790332 - samples/sec: 34.55\n",
      "2019-10-25 06:55:36,746 epoch 19 - iter 16/24 - loss 0.88605019 - samples/sec: 33.19\n",
      "2019-10-25 06:55:38,837 epoch 19 - iter 18/24 - loss 0.89564519 - samples/sec: 31.57\n",
      "2019-10-25 06:55:40,976 epoch 19 - iter 20/24 - loss 0.88883583 - samples/sec: 30.94\n",
      "2019-10-25 06:55:43,470 epoch 19 - iter 22/24 - loss 0.87687095 - samples/sec: 26.34\n",
      "2019-10-25 06:55:44,885 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:55:44,887 EPOCH 19 done: loss 0.8888 - lr 0.0500\n",
      "2019-10-25 06:55:58,024 DEV : loss 0.9964154362678528 - score 0.4939\n",
      "2019-10-25 06:55:58,143 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:56:00,931 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:56:13,468 epoch 20 - iter 0/24 - loss 0.81182015 - samples/sec: 69.54\n",
      "2019-10-25 06:56:15,367 epoch 20 - iter 2/24 - loss 0.89515070 - samples/sec: 34.63\n",
      "2019-10-25 06:56:17,209 epoch 20 - iter 4/24 - loss 0.88741877 - samples/sec: 35.77\n",
      "2019-10-25 06:56:18,915 epoch 20 - iter 6/24 - loss 0.89112138 - samples/sec: 39.23\n",
      "2019-10-25 06:56:20,623 epoch 20 - iter 8/24 - loss 0.89550502 - samples/sec: 38.57\n",
      "2019-10-25 06:56:22,567 epoch 20 - iter 10/24 - loss 0.88770139 - samples/sec: 33.81\n",
      "2019-10-25 06:56:24,600 epoch 20 - iter 12/24 - loss 0.89461389 - samples/sec: 32.81\n",
      "2019-10-25 06:56:26,838 epoch 20 - iter 14/24 - loss 0.92016075 - samples/sec: 29.19\n",
      "2019-10-25 06:56:28,737 epoch 20 - iter 16/24 - loss 0.91350234 - samples/sec: 34.91\n",
      "2019-10-25 06:56:30,408 epoch 20 - iter 18/24 - loss 0.89807109 - samples/sec: 40.23\n",
      "2019-10-25 06:56:32,278 epoch 20 - iter 20/24 - loss 0.88721106 - samples/sec: 35.05\n",
      "2019-10-25 06:56:34,057 epoch 20 - iter 22/24 - loss 0.88230889 - samples/sec: 36.99\n",
      "2019-10-25 06:56:35,429 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:56:35,431 EPOCH 20 done: loss 0.8867 - lr 0.0500\n",
      "2019-10-25 06:56:47,531 DEV : loss 1.038429856300354 - score 0.5\n",
      "2019-10-25 06:56:47,646 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 06:56:50,583 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:57:03,535 epoch 21 - iter 0/24 - loss 0.90236700 - samples/sec: 68.07\n",
      "2019-10-25 06:57:05,542 epoch 21 - iter 2/24 - loss 0.77650317 - samples/sec: 33.25\n",
      "2019-10-25 06:57:07,455 epoch 21 - iter 4/24 - loss 0.82266700 - samples/sec: 34.54\n",
      "2019-10-25 06:57:09,877 epoch 21 - iter 6/24 - loss 0.78577376 - samples/sec: 27.11\n",
      "2019-10-25 06:57:11,671 epoch 21 - iter 8/24 - loss 0.84039710 - samples/sec: 37.71\n",
      "2019-10-25 06:57:13,706 epoch 21 - iter 10/24 - loss 0.86178807 - samples/sec: 32.24\n",
      "2019-10-25 06:57:16,618 epoch 21 - iter 12/24 - loss 0.84492120 - samples/sec: 22.69\n",
      "2019-10-25 06:57:18,874 epoch 21 - iter 14/24 - loss 0.84762429 - samples/sec: 29.31\n",
      "2019-10-25 06:57:20,736 epoch 21 - iter 16/24 - loss 0.83958921 - samples/sec: 35.56\n",
      "2019-10-25 06:57:22,464 epoch 21 - iter 18/24 - loss 0.86629415 - samples/sec: 38.34\n",
      "2019-10-25 06:57:24,355 epoch 21 - iter 20/24 - loss 0.88038592 - samples/sec: 35.14\n",
      "2019-10-25 06:57:26,575 epoch 21 - iter 22/24 - loss 0.89056215 - samples/sec: 29.49\n",
      "2019-10-25 06:57:27,876 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:57:27,878 EPOCH 21 done: loss 0.8865 - lr 0.0500\n",
      "2019-10-25 06:57:40,585 DEV : loss 0.9999549388885498 - score 0.4939\n",
      "2019-10-25 06:57:40,702 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 06:57:40,704 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:57:53,314 epoch 22 - iter 0/24 - loss 0.58321959 - samples/sec: 86.74\n",
      "2019-10-25 06:57:55,203 epoch 22 - iter 2/24 - loss 0.78924054 - samples/sec: 35.20\n",
      "2019-10-25 06:57:57,227 epoch 22 - iter 4/24 - loss 0.79390684 - samples/sec: 32.76\n",
      "2019-10-25 06:57:59,107 epoch 22 - iter 6/24 - loss 0.76775266 - samples/sec: 35.20\n",
      "2019-10-25 06:58:01,416 epoch 22 - iter 8/24 - loss 0.76676803 - samples/sec: 28.58\n",
      "2019-10-25 06:58:03,531 epoch 22 - iter 10/24 - loss 0.77944194 - samples/sec: 31.60\n",
      "2019-10-25 06:58:05,658 epoch 22 - iter 12/24 - loss 0.78488254 - samples/sec: 31.08\n",
      "2019-10-25 06:58:07,711 epoch 22 - iter 14/24 - loss 0.82086537 - samples/sec: 32.26\n",
      "2019-10-25 06:58:09,756 epoch 22 - iter 16/24 - loss 0.82554529 - samples/sec: 32.58\n",
      "2019-10-25 06:58:12,100 epoch 22 - iter 18/24 - loss 0.83707222 - samples/sec: 28.69\n",
      "2019-10-25 06:58:14,623 epoch 22 - iter 20/24 - loss 0.84006925 - samples/sec: 26.15\n",
      "2019-10-25 06:58:17,295 epoch 22 - iter 22/24 - loss 0.84332529 - samples/sec: 24.51\n",
      "2019-10-25 06:58:18,949 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:58:18,951 EPOCH 22 done: loss 0.8381 - lr 0.0500\n",
      "2019-10-25 06:58:33,818 DEV : loss 0.9469084739685059 - score 0.4878\n",
      "2019-10-25 06:58:33,990 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 06:58:33,993 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:58:48,126 epoch 23 - iter 0/24 - loss 0.60555679 - samples/sec: 72.70\n",
      "2019-10-25 06:58:50,355 epoch 23 - iter 2/24 - loss 0.77534296 - samples/sec: 30.81\n",
      "2019-10-25 06:58:52,053 epoch 23 - iter 4/24 - loss 0.82492659 - samples/sec: 38.89\n",
      "2019-10-25 06:58:54,316 epoch 23 - iter 6/24 - loss 0.85544570 - samples/sec: 29.05\n",
      "2019-10-25 06:58:56,285 epoch 23 - iter 8/24 - loss 0.85951908 - samples/sec: 33.98\n",
      "2019-10-25 06:58:58,244 epoch 23 - iter 10/24 - loss 0.88882497 - samples/sec: 33.41\n",
      "2019-10-25 06:58:59,923 epoch 23 - iter 12/24 - loss 0.87959822 - samples/sec: 39.56\n",
      "2019-10-25 06:59:02,108 epoch 23 - iter 14/24 - loss 0.90581824 - samples/sec: 30.49\n",
      "2019-10-25 06:59:04,071 epoch 23 - iter 16/24 - loss 0.89129975 - samples/sec: 33.36\n",
      "2019-10-25 06:59:06,327 epoch 23 - iter 18/24 - loss 0.88610153 - samples/sec: 29.27\n",
      "2019-10-25 06:59:08,313 epoch 23 - iter 20/24 - loss 0.87585239 - samples/sec: 33.46\n",
      "2019-10-25 06:59:09,915 epoch 23 - iter 22/24 - loss 0.86866421 - samples/sec: 41.33\n",
      "2019-10-25 06:59:11,518 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:59:11,519 EPOCH 23 done: loss 0.8637 - lr 0.0500\n",
      "2019-10-25 06:59:25,387 DEV : loss 1.001334547996521 - score 0.4756\n",
      "2019-10-25 06:59:25,542 BAD EPOCHS (no improvement): 3\n",
      "2019-10-25 06:59:25,544 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 06:59:38,839 epoch 24 - iter 0/24 - loss 0.75790650 - samples/sec: 79.42\n",
      "2019-10-25 06:59:40,524 epoch 24 - iter 2/24 - loss 0.76513414 - samples/sec: 39.04\n",
      "2019-10-25 06:59:42,993 epoch 24 - iter 4/24 - loss 0.75632405 - samples/sec: 26.47\n",
      "2019-10-25 06:59:45,838 epoch 24 - iter 6/24 - loss 0.88506746 - samples/sec: 23.26\n",
      "2019-10-25 06:59:48,156 epoch 24 - iter 8/24 - loss 0.85942576 - samples/sec: 28.93\n",
      "2019-10-25 06:59:50,056 epoch 24 - iter 10/24 - loss 0.85948032 - samples/sec: 34.82\n",
      "2019-10-25 06:59:51,957 epoch 24 - iter 12/24 - loss 0.85359568 - samples/sec: 35.05\n",
      "2019-10-25 06:59:53,865 epoch 24 - iter 14/24 - loss 0.84109783 - samples/sec: 34.64\n",
      "2019-10-25 06:59:55,945 epoch 24 - iter 16/24 - loss 0.84796666 - samples/sec: 31.74\n",
      "2019-10-25 06:59:57,781 epoch 24 - iter 18/24 - loss 0.84434290 - samples/sec: 36.34\n",
      "2019-10-25 06:59:59,697 epoch 24 - iter 20/24 - loss 0.84196447 - samples/sec: 35.25\n",
      "2019-10-25 07:00:01,606 epoch 24 - iter 22/24 - loss 0.84497759 - samples/sec: 34.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:00:02,764 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:00:02,765 EPOCH 24 done: loss 0.8609 - lr 0.0500\n",
      "2019-10-25 07:00:16,926 DEV : loss 1.1886277198791504 - score 0.4573\n",
      "2019-10-25 07:00:17,052 BAD EPOCHS (no improvement): 4\n",
      "2019-10-25 07:00:17,054 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:00:30,296 epoch 25 - iter 0/24 - loss 0.94394559 - samples/sec: 71.82\n",
      "2019-10-25 07:00:32,452 epoch 25 - iter 2/24 - loss 0.85504725 - samples/sec: 30.78\n",
      "2019-10-25 07:00:34,511 epoch 25 - iter 4/24 - loss 0.86950293 - samples/sec: 31.92\n",
      "2019-10-25 07:00:36,385 epoch 25 - iter 6/24 - loss 0.83312696 - samples/sec: 35.53\n",
      "2019-10-25 07:00:38,298 epoch 25 - iter 8/24 - loss 0.82939079 - samples/sec: 34.59\n",
      "2019-10-25 07:00:40,451 epoch 25 - iter 10/24 - loss 0.78727212 - samples/sec: 30.52\n",
      "2019-10-25 07:00:42,359 epoch 25 - iter 12/24 - loss 0.80337936 - samples/sec: 34.83\n",
      "2019-10-25 07:00:44,252 epoch 25 - iter 14/24 - loss 0.81591507 - samples/sec: 34.95\n",
      "2019-10-25 07:00:46,230 epoch 25 - iter 16/24 - loss 0.84991948 - samples/sec: 33.16\n",
      "2019-10-25 07:00:48,138 epoch 25 - iter 18/24 - loss 0.86932907 - samples/sec: 34.77\n",
      "2019-10-25 07:00:50,534 epoch 25 - iter 20/24 - loss 0.86601631 - samples/sec: 34.25\n",
      "2019-10-25 07:00:52,213 epoch 25 - iter 22/24 - loss 0.86947478 - samples/sec: 39.23\n",
      "2019-10-25 07:00:53,438 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:00:53,440 EPOCH 25 done: loss 0.8608 - lr 0.0500\n",
      "2019-10-25 07:01:07,056 DEV : loss 0.9991998672485352 - score 0.5183\n",
      "2019-10-25 07:01:07,185 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:01:10,092 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:01:23,189 epoch 26 - iter 0/24 - loss 0.87013173 - samples/sec: 70.38\n",
      "2019-10-25 07:01:25,414 epoch 26 - iter 2/24 - loss 0.79812602 - samples/sec: 29.78\n",
      "2019-10-25 07:01:27,530 epoch 26 - iter 4/24 - loss 0.75593123 - samples/sec: 31.25\n",
      "2019-10-25 07:01:29,450 epoch 26 - iter 6/24 - loss 0.71944588 - samples/sec: 34.43\n",
      "2019-10-25 07:01:31,368 epoch 26 - iter 8/24 - loss 0.72502542 - samples/sec: 36.67\n",
      "2019-10-25 07:01:33,363 epoch 26 - iter 10/24 - loss 0.74357811 - samples/sec: 32.88\n",
      "2019-10-25 07:01:35,629 epoch 26 - iter 12/24 - loss 0.77348881 - samples/sec: 29.18\n",
      "2019-10-25 07:01:37,407 epoch 26 - iter 14/24 - loss 0.77614870 - samples/sec: 37.94\n",
      "2019-10-25 07:01:39,181 epoch 26 - iter 16/24 - loss 0.79962974 - samples/sec: 37.12\n",
      "2019-10-25 07:01:40,850 epoch 26 - iter 18/24 - loss 0.79861621 - samples/sec: 39.74\n",
      "2019-10-25 07:01:42,583 epoch 26 - iter 20/24 - loss 0.80461589 - samples/sec: 38.36\n",
      "2019-10-25 07:01:44,332 epoch 26 - iter 22/24 - loss 0.80474587 - samples/sec: 37.57\n",
      "2019-10-25 07:01:45,664 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:01:45,666 EPOCH 26 done: loss 0.8176 - lr 0.0500\n",
      "2019-10-25 07:01:59,126 DEV : loss 1.2017604112625122 - score 0.4817\n",
      "2019-10-25 07:01:59,246 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:01:59,249 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:02:11,901 epoch 27 - iter 0/24 - loss 1.12716258 - samples/sec: 81.73\n",
      "2019-10-25 07:02:13,744 epoch 27 - iter 2/24 - loss 0.89788504 - samples/sec: 36.10\n",
      "2019-10-25 07:02:15,690 epoch 27 - iter 4/24 - loss 0.78274454 - samples/sec: 33.73\n",
      "2019-10-25 07:02:17,407 epoch 27 - iter 6/24 - loss 0.75352665 - samples/sec: 38.86\n",
      "2019-10-25 07:02:19,392 epoch 27 - iter 8/24 - loss 0.83766247 - samples/sec: 33.31\n",
      "2019-10-25 07:02:21,007 epoch 27 - iter 10/24 - loss 0.82668017 - samples/sec: 40.89\n",
      "2019-10-25 07:02:23,039 epoch 27 - iter 12/24 - loss 0.83153220 - samples/sec: 32.53\n",
      "2019-10-25 07:02:25,407 epoch 27 - iter 14/24 - loss 0.81542987 - samples/sec: 34.70\n",
      "2019-10-25 07:02:27,249 epoch 27 - iter 16/24 - loss 0.82095597 - samples/sec: 35.86\n",
      "2019-10-25 07:02:29,001 epoch 27 - iter 18/24 - loss 0.82463974 - samples/sec: 37.82\n",
      "2019-10-25 07:02:30,931 epoch 27 - iter 20/24 - loss 0.81458561 - samples/sec: 34.48\n",
      "2019-10-25 07:02:32,990 epoch 27 - iter 22/24 - loss 0.84806593 - samples/sec: 31.88\n",
      "2019-10-25 07:02:34,418 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:02:34,419 EPOCH 27 done: loss 0.8478 - lr 0.0500\n",
      "2019-10-25 07:02:46,897 DEV : loss 1.141947865486145 - score 0.4268\n",
      "2019-10-25 07:02:47,027 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:02:47,029 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:03:01,393 epoch 28 - iter 0/24 - loss 0.96367025 - samples/sec: 51.76\n",
      "2019-10-25 07:03:03,631 epoch 28 - iter 2/24 - loss 0.96812514 - samples/sec: 29.45\n",
      "2019-10-25 07:03:05,711 epoch 28 - iter 4/24 - loss 0.97956178 - samples/sec: 32.34\n",
      "2019-10-25 07:03:07,912 epoch 28 - iter 6/24 - loss 0.92357395 - samples/sec: 30.25\n",
      "2019-10-25 07:03:09,873 epoch 28 - iter 8/24 - loss 0.89161889 - samples/sec: 34.12\n",
      "2019-10-25 07:03:11,742 epoch 28 - iter 10/24 - loss 0.86590502 - samples/sec: 35.30\n",
      "2019-10-25 07:03:13,611 epoch 28 - iter 12/24 - loss 0.85858843 - samples/sec: 35.55\n",
      "2019-10-25 07:03:15,546 epoch 28 - iter 14/24 - loss 0.84950999 - samples/sec: 34.30\n",
      "2019-10-25 07:03:18,135 epoch 28 - iter 16/24 - loss 0.84340948 - samples/sec: 25.60\n",
      "2019-10-25 07:03:19,888 epoch 28 - iter 18/24 - loss 0.83225287 - samples/sec: 38.12\n",
      "2019-10-25 07:03:22,006 epoch 28 - iter 20/24 - loss 0.80658154 - samples/sec: 31.11\n",
      "2019-10-25 07:03:24,333 epoch 28 - iter 22/24 - loss 0.81361003 - samples/sec: 28.20\n",
      "2019-10-25 07:03:25,820 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:03:25,822 EPOCH 28 done: loss 0.8162 - lr 0.0500\n",
      "2019-10-25 07:03:39,265 DEV : loss 1.0383728742599487 - score 0.5427\n",
      "2019-10-25 07:03:39,445 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:03:42,463 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:03:55,498 epoch 29 - iter 0/24 - loss 0.85295379 - samples/sec: 72.74\n",
      "2019-10-25 07:03:57,651 epoch 29 - iter 2/24 - loss 0.68452830 - samples/sec: 30.70\n",
      "2019-10-25 07:03:59,326 epoch 29 - iter 4/24 - loss 0.78557112 - samples/sec: 39.73\n",
      "2019-10-25 07:04:01,116 epoch 29 - iter 6/24 - loss 0.81136972 - samples/sec: 36.92\n",
      "2019-10-25 07:04:02,957 epoch 29 - iter 8/24 - loss 0.81197216 - samples/sec: 36.02\n",
      "2019-10-25 07:04:04,729 epoch 29 - iter 10/24 - loss 0.83275716 - samples/sec: 37.39\n",
      "2019-10-25 07:04:06,636 epoch 29 - iter 12/24 - loss 0.84116245 - samples/sec: 34.63\n",
      "2019-10-25 07:04:08,952 epoch 29 - iter 14/24 - loss 0.82378206 - samples/sec: 35.74\n",
      "2019-10-25 07:04:10,969 epoch 29 - iter 16/24 - loss 0.80175044 - samples/sec: 32.67\n",
      "2019-10-25 07:04:12,806 epoch 29 - iter 18/24 - loss 0.77438463 - samples/sec: 36.16\n",
      "2019-10-25 07:04:14,531 epoch 29 - iter 20/24 - loss 0.77997137 - samples/sec: 38.40\n",
      "2019-10-25 07:04:16,581 epoch 29 - iter 22/24 - loss 0.81198062 - samples/sec: 32.11\n",
      "2019-10-25 07:04:17,980 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:04:17,982 EPOCH 29 done: loss 0.8171 - lr 0.0500\n",
      "2019-10-25 07:04:30,578 DEV : loss 1.0753097534179688 - score 0.5\n",
      "2019-10-25 07:04:30,704 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:04:30,706 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:04:44,682 epoch 30 - iter 0/24 - loss 1.23255551 - samples/sec: 58.26\n",
      "2019-10-25 07:04:46,821 epoch 30 - iter 2/24 - loss 0.99244414 - samples/sec: 30.92\n",
      "2019-10-25 07:04:48,844 epoch 30 - iter 4/24 - loss 0.88746001 - samples/sec: 32.41\n",
      "2019-10-25 07:04:51,551 epoch 30 - iter 6/24 - loss 0.83585292 - samples/sec: 24.49\n",
      "2019-10-25 07:04:53,950 epoch 30 - iter 8/24 - loss 0.83313604 - samples/sec: 27.42\n",
      "2019-10-25 07:04:56,325 epoch 30 - iter 10/24 - loss 0.85145291 - samples/sec: 27.96\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:04:58,626 epoch 30 - iter 12/24 - loss 0.88741197 - samples/sec: 28.94\n",
      "2019-10-25 07:05:00,785 epoch 30 - iter 14/24 - loss 0.85185355 - samples/sec: 30.79\n",
      "2019-10-25 07:05:02,956 epoch 30 - iter 16/24 - loss 0.84680405 - samples/sec: 30.14\n",
      "2019-10-25 07:05:04,825 epoch 30 - iter 18/24 - loss 0.84991322 - samples/sec: 35.63\n",
      "2019-10-25 07:05:07,172 epoch 30 - iter 20/24 - loss 0.83271367 - samples/sec: 27.96\n",
      "2019-10-25 07:05:09,398 epoch 30 - iter 22/24 - loss 0.82647971 - samples/sec: 29.42\n",
      "2019-10-25 07:05:10,547 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:05:10,548 EPOCH 30 done: loss 0.8452 - lr 0.0500\n",
      "2019-10-25 07:05:23,707 DEV : loss 1.1903170347213745 - score 0.4573\n",
      "2019-10-25 07:05:23,876 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:05:23,879 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:05:37,868 epoch 31 - iter 0/24 - loss 1.02131307 - samples/sec: 76.49\n",
      "2019-10-25 07:05:39,854 epoch 31 - iter 2/24 - loss 0.85980278 - samples/sec: 33.50\n",
      "2019-10-25 07:05:41,665 epoch 31 - iter 4/24 - loss 0.82642953 - samples/sec: 36.24\n",
      "2019-10-25 07:05:43,418 epoch 31 - iter 6/24 - loss 0.83814501 - samples/sec: 37.90\n",
      "2019-10-25 07:05:45,636 epoch 31 - iter 8/24 - loss 0.85029917 - samples/sec: 29.89\n",
      "2019-10-25 07:05:47,670 epoch 31 - iter 10/24 - loss 0.82815786 - samples/sec: 32.31\n",
      "2019-10-25 07:05:50,058 epoch 31 - iter 12/24 - loss 0.80259982 - samples/sec: 34.34\n",
      "2019-10-25 07:05:52,001 epoch 31 - iter 14/24 - loss 0.80297997 - samples/sec: 34.03\n",
      "2019-10-25 07:05:54,082 epoch 31 - iter 16/24 - loss 0.79271517 - samples/sec: 31.74\n",
      "2019-10-25 07:05:55,919 epoch 31 - iter 18/24 - loss 0.80898195 - samples/sec: 36.38\n",
      "2019-10-25 07:05:57,805 epoch 31 - iter 20/24 - loss 0.82154652 - samples/sec: 35.41\n",
      "2019-10-25 07:05:59,647 epoch 31 - iter 22/24 - loss 0.81487574 - samples/sec: 36.65\n",
      "2019-10-25 07:06:00,781 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:06:00,783 EPOCH 31 done: loss 0.8175 - lr 0.0500\n",
      "2019-10-25 07:06:13,395 DEV : loss 0.92280513048172 - score 0.5366\n",
      "2019-10-25 07:06:13,540 BAD EPOCHS (no improvement): 3\n",
      "2019-10-25 07:06:13,543 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:06:26,722 epoch 32 - iter 0/24 - loss 0.91010869 - samples/sec: 64.60\n",
      "2019-10-25 07:06:28,591 epoch 32 - iter 2/24 - loss 0.76975918 - samples/sec: 35.85\n",
      "2019-10-25 07:06:30,446 epoch 32 - iter 4/24 - loss 0.80500605 - samples/sec: 35.36\n",
      "2019-10-25 07:06:32,258 epoch 32 - iter 6/24 - loss 0.79368310 - samples/sec: 36.77\n",
      "2019-10-25 07:06:34,229 epoch 32 - iter 8/24 - loss 0.81343464 - samples/sec: 33.45\n",
      "2019-10-25 07:06:36,258 epoch 32 - iter 10/24 - loss 0.80012923 - samples/sec: 32.33\n",
      "2019-10-25 07:06:38,412 epoch 32 - iter 12/24 - loss 0.79825978 - samples/sec: 30.80\n",
      "2019-10-25 07:06:40,238 epoch 32 - iter 14/24 - loss 0.81030759 - samples/sec: 36.33\n",
      "2019-10-25 07:06:42,208 epoch 32 - iter 16/24 - loss 0.78931763 - samples/sec: 33.33\n",
      "2019-10-25 07:06:44,225 epoch 32 - iter 18/24 - loss 0.80683866 - samples/sec: 33.00\n",
      "2019-10-25 07:06:46,644 epoch 32 - iter 20/24 - loss 0.80676571 - samples/sec: 27.46\n",
      "2019-10-25 07:06:48,572 epoch 32 - iter 22/24 - loss 0.81062350 - samples/sec: 34.04\n",
      "2019-10-25 07:06:49,955 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:06:49,957 EPOCH 32 done: loss 0.8222 - lr 0.0500\n",
      "2019-10-25 07:07:03,073 DEV : loss 1.0496705770492554 - score 0.5061\n",
      "2019-10-25 07:07:03,199 BAD EPOCHS (no improvement): 4\n",
      "2019-10-25 07:07:03,201 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:07:16,085 epoch 33 - iter 0/24 - loss 0.86924720 - samples/sec: 62.31\n",
      "2019-10-25 07:07:18,104 epoch 33 - iter 2/24 - loss 0.84770006 - samples/sec: 32.78\n",
      "2019-10-25 07:07:20,154 epoch 33 - iter 4/24 - loss 0.87619030 - samples/sec: 32.46\n",
      "2019-10-25 07:07:22,535 epoch 33 - iter 6/24 - loss 0.86862629 - samples/sec: 34.64\n",
      "2019-10-25 07:07:24,635 epoch 33 - iter 8/24 - loss 0.84687665 - samples/sec: 31.28\n",
      "2019-10-25 07:07:26,627 epoch 33 - iter 10/24 - loss 0.83707769 - samples/sec: 33.16\n",
      "2019-10-25 07:07:28,503 epoch 33 - iter 12/24 - loss 0.81126070 - samples/sec: 35.30\n",
      "2019-10-25 07:07:30,264 epoch 33 - iter 14/24 - loss 0.79751438 - samples/sec: 37.48\n",
      "2019-10-25 07:07:32,475 epoch 33 - iter 16/24 - loss 0.78017725 - samples/sec: 29.85\n",
      "2019-10-25 07:07:34,649 epoch 33 - iter 18/24 - loss 0.77576536 - samples/sec: 30.67\n",
      "2019-10-25 07:07:36,738 epoch 33 - iter 20/24 - loss 0.77532096 - samples/sec: 31.54\n",
      "2019-10-25 07:07:38,432 epoch 33 - iter 22/24 - loss 0.76820615 - samples/sec: 39.13\n",
      "2019-10-25 07:07:39,679 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:07:39,681 EPOCH 33 done: loss 0.7608 - lr 0.0500\n",
      "2019-10-25 07:07:52,342 DEV : loss 1.0258796215057373 - score 0.4878\n",
      "2019-10-25 07:07:52,479 BAD EPOCHS (no improvement): 5\n",
      "2019-10-25 07:07:52,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:08:05,466 epoch 34 - iter 0/24 - loss 0.64463991 - samples/sec: 71.14\n",
      "2019-10-25 07:08:07,356 epoch 34 - iter 2/24 - loss 0.59792191 - samples/sec: 35.08\n",
      "2019-10-25 07:08:09,252 epoch 34 - iter 4/24 - loss 0.67942638 - samples/sec: 34.75\n",
      "2019-10-25 07:08:11,446 epoch 34 - iter 6/24 - loss 0.76550245 - samples/sec: 30.17\n",
      "2019-10-25 07:08:13,107 epoch 34 - iter 8/24 - loss 0.78727096 - samples/sec: 40.02\n",
      "2019-10-25 07:08:15,148 epoch 34 - iter 10/24 - loss 0.75982996 - samples/sec: 32.17\n",
      "2019-10-25 07:08:16,992 epoch 34 - iter 12/24 - loss 0.79009194 - samples/sec: 36.05\n",
      "2019-10-25 07:08:18,924 epoch 34 - iter 14/24 - loss 0.79788990 - samples/sec: 34.14\n",
      "2019-10-25 07:08:20,597 epoch 34 - iter 16/24 - loss 0.82820508 - samples/sec: 39.64\n",
      "2019-10-25 07:08:22,507 epoch 34 - iter 18/24 - loss 0.83337966 - samples/sec: 34.60\n",
      "2019-10-25 07:08:24,730 epoch 34 - iter 20/24 - loss 0.83663580 - samples/sec: 29.62\n",
      "2019-10-25 07:08:26,792 epoch 34 - iter 22/24 - loss 0.81810519 - samples/sec: 31.88\n",
      "2019-10-25 07:08:28,269 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:08:28,270 EPOCH 34 done: loss 0.8208 - lr 0.0500\n",
      "2019-10-25 07:08:40,892 DEV : loss 0.9607009291648865 - score 0.5732\n",
      "2019-10-25 07:08:41,018 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:08:44,060 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:08:57,069 epoch 35 - iter 0/24 - loss 0.84933406 - samples/sec: 64.62\n",
      "2019-10-25 07:08:59,260 epoch 35 - iter 2/24 - loss 0.84465317 - samples/sec: 29.87\n",
      "2019-10-25 07:09:01,120 epoch 35 - iter 4/24 - loss 0.82778167 - samples/sec: 35.30\n",
      "2019-10-25 07:09:03,127 epoch 35 - iter 6/24 - loss 0.77281553 - samples/sec: 33.32\n",
      "2019-10-25 07:09:05,067 epoch 35 - iter 8/24 - loss 0.75693671 - samples/sec: 33.83\n",
      "2019-10-25 07:09:07,092 epoch 35 - iter 10/24 - loss 0.71752015 - samples/sec: 32.57\n",
      "2019-10-25 07:09:08,947 epoch 35 - iter 12/24 - loss 0.72773315 - samples/sec: 36.06\n",
      "2019-10-25 07:09:10,811 epoch 35 - iter 14/24 - loss 0.76048443 - samples/sec: 35.18\n",
      "2019-10-25 07:09:12,659 epoch 35 - iter 16/24 - loss 0.77185662 - samples/sec: 35.82\n",
      "2019-10-25 07:09:15,021 epoch 35 - iter 18/24 - loss 0.78353305 - samples/sec: 28.02\n",
      "2019-10-25 07:09:16,866 epoch 35 - iter 20/24 - loss 0.79719087 - samples/sec: 35.59\n",
      "2019-10-25 07:09:18,910 epoch 35 - iter 22/24 - loss 0.80349275 - samples/sec: 32.26\n",
      "2019-10-25 07:09:20,192 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:09:20,194 EPOCH 35 done: loss 0.7994 - lr 0.0500\n",
      "2019-10-25 07:09:32,969 DEV : loss 1.0469040870666504 - score 0.5122\n",
      "2019-10-25 07:09:33,099 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:09:33,101 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:09:46,153 epoch 36 - iter 0/24 - loss 0.70948285 - samples/sec: 64.61\n",
      "2019-10-25 07:09:48,258 epoch 36 - iter 2/24 - loss 0.73492930 - samples/sec: 31.68\n",
      "2019-10-25 07:09:50,244 epoch 36 - iter 4/24 - loss 0.75701809 - samples/sec: 32.97\n",
      "2019-10-25 07:09:52,093 epoch 36 - iter 6/24 - loss 0.71667857 - samples/sec: 35.81\n",
      "2019-10-25 07:09:54,275 epoch 36 - iter 8/24 - loss 0.79711223 - samples/sec: 30.37\n",
      "2019-10-25 07:09:56,328 epoch 36 - iter 10/24 - loss 0.79278141 - samples/sec: 31.96\n",
      "2019-10-25 07:09:58,286 epoch 36 - iter 12/24 - loss 0.80666047 - samples/sec: 33.83\n",
      "2019-10-25 07:10:00,111 epoch 36 - iter 14/24 - loss 0.79713227 - samples/sec: 36.43\n",
      "2019-10-25 07:10:02,115 epoch 36 - iter 16/24 - loss 0.78026264 - samples/sec: 32.84\n",
      "2019-10-25 07:10:04,118 epoch 36 - iter 18/24 - loss 0.77524734 - samples/sec: 32.87\n",
      "2019-10-25 07:10:06,001 epoch 36 - iter 20/24 - loss 0.77600465 - samples/sec: 35.60\n",
      "2019-10-25 07:10:07,753 epoch 36 - iter 22/24 - loss 0.78334551 - samples/sec: 37.87\n",
      "2019-10-25 07:10:09,035 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:10:09,036 EPOCH 36 done: loss 0.7897 - lr 0.0500\n",
      "2019-10-25 07:10:22,671 DEV : loss 0.9590300917625427 - score 0.5183\n",
      "2019-10-25 07:10:22,800 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:10:22,802 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:10:35,847 epoch 37 - iter 0/24 - loss 0.95968449 - samples/sec: 73.49\n",
      "2019-10-25 07:10:38,008 epoch 37 - iter 2/24 - loss 0.90674510 - samples/sec: 31.55\n",
      "2019-10-25 07:10:40,001 epoch 37 - iter 4/24 - loss 0.80827783 - samples/sec: 33.03\n",
      "2019-10-25 07:10:42,001 epoch 37 - iter 6/24 - loss 0.80994319 - samples/sec: 33.13\n",
      "2019-10-25 07:10:44,229 epoch 37 - iter 8/24 - loss 0.75085242 - samples/sec: 29.55\n",
      "2019-10-25 07:10:46,365 epoch 37 - iter 10/24 - loss 0.76845230 - samples/sec: 30.80\n",
      "2019-10-25 07:10:48,220 epoch 37 - iter 12/24 - loss 0.79701493 - samples/sec: 35.72\n",
      "2019-10-25 07:10:49,997 epoch 37 - iter 14/24 - loss 0.80144383 - samples/sec: 37.27\n",
      "2019-10-25 07:10:51,851 epoch 37 - iter 16/24 - loss 0.81044252 - samples/sec: 35.57\n",
      "2019-10-25 07:10:53,775 epoch 37 - iter 18/24 - loss 0.79572822 - samples/sec: 34.54\n",
      "2019-10-25 07:10:55,717 epoch 37 - iter 20/24 - loss 0.77688438 - samples/sec: 34.32\n",
      "2019-10-25 07:10:57,813 epoch 37 - iter 22/24 - loss 0.76968398 - samples/sec: 31.44\n",
      "2019-10-25 07:10:58,922 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:10:58,923 EPOCH 37 done: loss 0.7574 - lr 0.0500\n",
      "2019-10-25 07:11:11,846 DEV : loss 0.8854014873504639 - score 0.5915\n",
      "2019-10-25 07:11:11,968 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:11:15,087 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:11:28,404 epoch 38 - iter 0/24 - loss 0.71096176 - samples/sec: 62.60\n",
      "2019-10-25 07:11:30,253 epoch 38 - iter 2/24 - loss 0.86386400 - samples/sec: 35.62\n",
      "2019-10-25 07:11:32,115 epoch 38 - iter 4/24 - loss 0.80015136 - samples/sec: 35.33\n",
      "2019-10-25 07:11:34,066 epoch 38 - iter 6/24 - loss 0.83678338 - samples/sec: 34.06\n",
      "2019-10-25 07:11:36,173 epoch 38 - iter 8/24 - loss 0.84487196 - samples/sec: 31.35\n",
      "2019-10-25 07:11:37,955 epoch 38 - iter 10/24 - loss 0.83682363 - samples/sec: 37.17\n",
      "2019-10-25 07:11:39,947 epoch 38 - iter 12/24 - loss 0.81370861 - samples/sec: 34.22\n",
      "2019-10-25 07:11:41,887 epoch 38 - iter 14/24 - loss 0.82670359 - samples/sec: 34.06\n",
      "2019-10-25 07:11:43,679 epoch 38 - iter 16/24 - loss 0.80378093 - samples/sec: 36.83\n",
      "2019-10-25 07:11:45,519 epoch 38 - iter 18/24 - loss 0.80298269 - samples/sec: 36.33\n",
      "2019-10-25 07:11:47,704 epoch 38 - iter 20/24 - loss 0.80132347 - samples/sec: 30.21\n",
      "2019-10-25 07:11:49,485 epoch 38 - iter 22/24 - loss 0.80876529 - samples/sec: 37.05\n",
      "2019-10-25 07:11:50,709 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:11:50,711 EPOCH 38 done: loss 0.8033 - lr 0.0500\n",
      "2019-10-25 07:12:04,321 DEV : loss 0.982677698135376 - score 0.5122\n",
      "2019-10-25 07:12:04,466 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:12:04,470 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:12:17,019 epoch 39 - iter 0/24 - loss 0.64680082 - samples/sec: 70.52\n",
      "2019-10-25 07:12:18,938 epoch 39 - iter 2/24 - loss 0.69208894 - samples/sec: 34.69\n",
      "2019-10-25 07:12:20,893 epoch 39 - iter 4/24 - loss 0.73675679 - samples/sec: 33.60\n",
      "2019-10-25 07:12:22,750 epoch 39 - iter 6/24 - loss 0.78265521 - samples/sec: 35.71\n",
      "2019-10-25 07:12:24,776 epoch 39 - iter 8/24 - loss 0.78988388 - samples/sec: 32.82\n",
      "2019-10-25 07:12:26,630 epoch 39 - iter 10/24 - loss 0.73871775 - samples/sec: 35.40\n",
      "2019-10-25 07:12:28,949 epoch 39 - iter 12/24 - loss 0.74191509 - samples/sec: 28.33\n",
      "2019-10-25 07:12:31,475 epoch 39 - iter 14/24 - loss 0.74873682 - samples/sec: 26.66\n",
      "2019-10-25 07:12:33,728 epoch 39 - iter 16/24 - loss 0.76632990 - samples/sec: 29.11\n",
      "2019-10-25 07:12:35,825 epoch 39 - iter 18/24 - loss 0.76319534 - samples/sec: 32.60\n",
      "2019-10-25 07:12:37,795 epoch 39 - iter 20/24 - loss 0.74605303 - samples/sec: 34.12\n",
      "2019-10-25 07:12:39,661 epoch 39 - iter 22/24 - loss 0.75836664 - samples/sec: 35.29\n",
      "2019-10-25 07:12:41,024 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:12:41,026 EPOCH 39 done: loss 0.7559 - lr 0.0500\n",
      "2019-10-25 07:12:54,313 DEV : loss 0.9435173869132996 - score 0.5732\n",
      "2019-10-25 07:12:54,457 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:12:54,459 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:13:08,272 epoch 40 - iter 0/24 - loss 0.51907486 - samples/sec: 65.58\n",
      "2019-10-25 07:13:10,323 epoch 40 - iter 2/24 - loss 0.65766033 - samples/sec: 32.18\n",
      "2019-10-25 07:13:12,423 epoch 40 - iter 4/24 - loss 0.66530197 - samples/sec: 31.52\n",
      "2019-10-25 07:13:14,360 epoch 40 - iter 6/24 - loss 0.72133051 - samples/sec: 34.44\n",
      "2019-10-25 07:13:16,965 epoch 40 - iter 8/24 - loss 0.73977559 - samples/sec: 25.01\n",
      "2019-10-25 07:13:19,499 epoch 40 - iter 10/24 - loss 0.74981859 - samples/sec: 26.44\n",
      "2019-10-25 07:13:21,700 epoch 40 - iter 12/24 - loss 0.77594556 - samples/sec: 30.24\n",
      "2019-10-25 07:13:23,803 epoch 40 - iter 14/24 - loss 0.77544193 - samples/sec: 31.14\n",
      "2019-10-25 07:13:25,951 epoch 40 - iter 16/24 - loss 0.77172872 - samples/sec: 31.06\n",
      "2019-10-25 07:13:27,997 epoch 40 - iter 18/24 - loss 0.78182356 - samples/sec: 32.56\n",
      "2019-10-25 07:13:30,555 epoch 40 - iter 20/24 - loss 0.77096851 - samples/sec: 25.57\n",
      "2019-10-25 07:13:33,541 epoch 40 - iter 22/24 - loss 0.76882979 - samples/sec: 22.63\n",
      "2019-10-25 07:13:35,381 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:13:35,384 EPOCH 40 done: loss 0.7624 - lr 0.0500\n",
      "2019-10-25 07:13:50,640 DEV : loss 0.8648872375488281 - score 0.6037\n",
      "2019-10-25 07:13:50,771 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:13:53,671 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:14:05,638 epoch 41 - iter 0/24 - loss 0.45494303 - samples/sec: 77.70\n",
      "2019-10-25 07:14:07,543 epoch 41 - iter 2/24 - loss 0.58830473 - samples/sec: 34.73\n",
      "2019-10-25 07:14:09,284 epoch 41 - iter 4/24 - loss 0.64917716 - samples/sec: 37.85\n",
      "2019-10-25 07:14:11,032 epoch 41 - iter 6/24 - loss 0.72092175 - samples/sec: 38.19\n",
      "2019-10-25 07:14:12,913 epoch 41 - iter 8/24 - loss 0.72081205 - samples/sec: 34.98\n",
      "2019-10-25 07:14:15,253 epoch 41 - iter 10/24 - loss 0.72892847 - samples/sec: 28.17\n",
      "2019-10-25 07:14:17,621 epoch 41 - iter 12/24 - loss 0.76161287 - samples/sec: 28.13\n",
      "2019-10-25 07:14:19,574 epoch 41 - iter 14/24 - loss 0.74749075 - samples/sec: 33.75\n",
      "2019-10-25 07:14:21,531 epoch 41 - iter 16/24 - loss 0.74405354 - samples/sec: 33.59\n",
      "2019-10-25 07:14:23,236 epoch 41 - iter 18/24 - loss 0.73220473 - samples/sec: 39.19\n",
      "2019-10-25 07:14:25,535 epoch 41 - iter 20/24 - loss 0.71857513 - samples/sec: 28.61\n",
      "2019-10-25 07:14:27,902 epoch 41 - iter 22/24 - loss 0.72447271 - samples/sec: 27.99\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:14:29,425 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:14:29,426 EPOCH 41 done: loss 0.7346 - lr 0.0500\n",
      "2019-10-25 07:14:43,032 DEV : loss 1.0040267705917358 - score 0.5488\n",
      "2019-10-25 07:14:43,160 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:14:43,162 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:14:56,854 epoch 42 - iter 0/24 - loss 0.89064580 - samples/sec: 80.42\n",
      "2019-10-25 07:14:58,664 epoch 42 - iter 2/24 - loss 0.86089611 - samples/sec: 36.57\n",
      "2019-10-25 07:15:00,564 epoch 42 - iter 4/24 - loss 0.76156485 - samples/sec: 34.64\n",
      "2019-10-25 07:15:02,579 epoch 42 - iter 6/24 - loss 0.76644603 - samples/sec: 32.74\n",
      "2019-10-25 07:15:04,389 epoch 42 - iter 8/24 - loss 0.74369063 - samples/sec: 36.92\n",
      "2019-10-25 07:15:06,559 epoch 42 - iter 10/24 - loss 0.76964226 - samples/sec: 30.20\n",
      "2019-10-25 07:15:08,254 epoch 42 - iter 12/24 - loss 0.76441601 - samples/sec: 39.06\n",
      "2019-10-25 07:15:09,908 epoch 42 - iter 14/24 - loss 0.73823233 - samples/sec: 40.17\n",
      "2019-10-25 07:15:11,836 epoch 42 - iter 16/24 - loss 0.72078076 - samples/sec: 34.18\n",
      "2019-10-25 07:15:13,524 epoch 42 - iter 18/24 - loss 0.72973469 - samples/sec: 39.22\n",
      "2019-10-25 07:15:15,334 epoch 42 - iter 20/24 - loss 0.73662532 - samples/sec: 36.78\n",
      "2019-10-25 07:15:17,089 epoch 42 - iter 22/24 - loss 0.75320786 - samples/sec: 37.68\n",
      "2019-10-25 07:15:18,241 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:15:18,243 EPOCH 42 done: loss 0.7583 - lr 0.0500\n",
      "2019-10-25 07:15:30,234 DEV : loss 0.95309978723526 - score 0.5854\n",
      "2019-10-25 07:15:30,351 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:15:30,353 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:15:41,932 epoch 43 - iter 0/24 - loss 0.81589341 - samples/sec: 83.56\n",
      "2019-10-25 07:15:43,638 epoch 43 - iter 2/24 - loss 0.84614509 - samples/sec: 38.74\n",
      "2019-10-25 07:15:45,658 epoch 43 - iter 4/24 - loss 0.75479341 - samples/sec: 32.86\n",
      "2019-10-25 07:15:47,495 epoch 43 - iter 6/24 - loss 0.74121843 - samples/sec: 36.31\n",
      "2019-10-25 07:15:49,300 epoch 43 - iter 8/24 - loss 0.74713070 - samples/sec: 36.37\n",
      "2019-10-25 07:15:51,639 epoch 43 - iter 10/24 - loss 0.68784878 - samples/sec: 28.09\n",
      "2019-10-25 07:15:54,281 epoch 43 - iter 12/24 - loss 0.65202132 - samples/sec: 25.19\n",
      "2019-10-25 07:15:56,564 epoch 43 - iter 14/24 - loss 0.66692389 - samples/sec: 28.79\n",
      "2019-10-25 07:15:58,143 epoch 43 - iter 16/24 - loss 0.69114677 - samples/sec: 42.02\n",
      "2019-10-25 07:15:59,854 epoch 43 - iter 18/24 - loss 0.69731507 - samples/sec: 38.92\n",
      "2019-10-25 07:16:01,457 epoch 43 - iter 20/24 - loss 0.71410854 - samples/sec: 41.00\n",
      "2019-10-25 07:16:03,329 epoch 43 - iter 22/24 - loss 0.70192539 - samples/sec: 35.26\n",
      "2019-10-25 07:16:04,731 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:16:04,733 EPOCH 43 done: loss 0.7042 - lr 0.0500\n",
      "2019-10-25 07:16:17,307 DEV : loss 0.8294395804405212 - score 0.6341\n",
      "2019-10-25 07:16:17,424 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:16:20,342 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:16:32,335 epoch 44 - iter 0/24 - loss 0.61263895 - samples/sec: 72.35\n",
      "2019-10-25 07:16:34,167 epoch 44 - iter 2/24 - loss 0.95312550 - samples/sec: 35.86\n",
      "2019-10-25 07:16:36,108 epoch 44 - iter 4/24 - loss 0.90106391 - samples/sec: 34.04\n",
      "2019-10-25 07:16:37,962 epoch 44 - iter 6/24 - loss 0.87337796 - samples/sec: 36.62\n",
      "2019-10-25 07:16:39,684 epoch 44 - iter 8/24 - loss 0.81418593 - samples/sec: 39.15\n",
      "2019-10-25 07:16:41,479 epoch 44 - iter 10/24 - loss 0.75738863 - samples/sec: 36.77\n",
      "2019-10-25 07:16:43,287 epoch 44 - iter 12/24 - loss 0.78689905 - samples/sec: 36.92\n",
      "2019-10-25 07:16:45,205 epoch 44 - iter 14/24 - loss 0.79404057 - samples/sec: 34.24\n",
      "2019-10-25 07:16:47,132 epoch 44 - iter 16/24 - loss 0.76278676 - samples/sec: 34.26\n",
      "2019-10-25 07:16:48,726 epoch 44 - iter 18/24 - loss 0.77308684 - samples/sec: 42.11\n",
      "2019-10-25 07:16:50,408 epoch 44 - iter 20/24 - loss 0.76854103 - samples/sec: 39.02\n",
      "2019-10-25 07:16:52,742 epoch 44 - iter 22/24 - loss 0.76214758 - samples/sec: 34.85\n",
      "2019-10-25 07:16:54,046 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:16:54,048 EPOCH 44 done: loss 0.7692 - lr 0.0500\n",
      "2019-10-25 07:17:06,270 DEV : loss 0.9256040453910828 - score 0.5854\n",
      "2019-10-25 07:17:06,389 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:17:06,391 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:17:18,463 epoch 45 - iter 0/24 - loss 0.62869960 - samples/sec: 68.03\n",
      "2019-10-25 07:17:20,223 epoch 45 - iter 2/24 - loss 0.63257616 - samples/sec: 37.50\n",
      "2019-10-25 07:17:22,017 epoch 45 - iter 4/24 - loss 0.90314716 - samples/sec: 36.81\n",
      "2019-10-25 07:17:23,893 epoch 45 - iter 6/24 - loss 0.85151204 - samples/sec: 35.36\n",
      "2019-10-25 07:17:25,675 epoch 45 - iter 8/24 - loss 0.82027895 - samples/sec: 37.38\n",
      "2019-10-25 07:17:27,494 epoch 45 - iter 10/24 - loss 0.80915905 - samples/sec: 37.37\n",
      "2019-10-25 07:17:29,393 epoch 45 - iter 12/24 - loss 0.78223116 - samples/sec: 34.88\n",
      "2019-10-25 07:17:31,051 epoch 45 - iter 14/24 - loss 0.77961990 - samples/sec: 39.94\n",
      "2019-10-25 07:17:32,707 epoch 45 - iter 16/24 - loss 0.79740607 - samples/sec: 39.92\n",
      "2019-10-25 07:17:34,670 epoch 45 - iter 18/24 - loss 0.79310533 - samples/sec: 33.72\n",
      "2019-10-25 07:17:36,734 epoch 45 - iter 20/24 - loss 0.77753186 - samples/sec: 31.93\n",
      "2019-10-25 07:17:38,696 epoch 45 - iter 22/24 - loss 0.78010739 - samples/sec: 33.65\n",
      "2019-10-25 07:17:39,719 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:17:39,720 EPOCH 45 done: loss 0.7832 - lr 0.0500\n",
      "2019-10-25 07:17:51,239 DEV : loss 0.8603203296661377 - score 0.6159\n",
      "2019-10-25 07:17:51,352 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:17:51,354 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:18:03,618 epoch 46 - iter 0/24 - loss 0.42501184 - samples/sec: 76.22\n",
      "2019-10-25 07:18:05,305 epoch 46 - iter 2/24 - loss 0.69064427 - samples/sec: 39.23\n",
      "2019-10-25 07:18:06,999 epoch 46 - iter 4/24 - loss 0.71061390 - samples/sec: 39.19\n",
      "2019-10-25 07:18:08,682 epoch 46 - iter 6/24 - loss 0.70822303 - samples/sec: 39.78\n",
      "2019-10-25 07:18:10,336 epoch 46 - iter 8/24 - loss 0.70339000 - samples/sec: 39.73\n",
      "2019-10-25 07:18:11,956 epoch 46 - iter 10/24 - loss 0.72690586 - samples/sec: 40.88\n",
      "2019-10-25 07:18:13,698 epoch 46 - iter 12/24 - loss 0.70107963 - samples/sec: 38.42\n",
      "2019-10-25 07:18:15,443 epoch 46 - iter 14/24 - loss 0.69607658 - samples/sec: 37.71\n",
      "2019-10-25 07:18:17,509 epoch 46 - iter 16/24 - loss 0.70227074 - samples/sec: 31.81\n",
      "2019-10-25 07:18:19,664 epoch 46 - iter 18/24 - loss 0.68883417 - samples/sec: 39.33\n",
      "2019-10-25 07:18:21,518 epoch 46 - iter 20/24 - loss 0.68280844 - samples/sec: 35.39\n",
      "2019-10-25 07:18:23,229 epoch 46 - iter 22/24 - loss 0.70806247 - samples/sec: 38.56\n",
      "2019-10-25 07:18:24,587 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:18:24,588 EPOCH 46 done: loss 0.7114 - lr 0.0500\n",
      "2019-10-25 07:18:36,210 DEV : loss 0.8631021976470947 - score 0.622\n",
      "2019-10-25 07:18:36,318 BAD EPOCHS (no improvement): 3\n",
      "2019-10-25 07:18:36,320 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:18:47,874 epoch 47 - iter 0/24 - loss 0.52221280 - samples/sec: 83.23\n",
      "2019-10-25 07:18:49,504 epoch 47 - iter 2/24 - loss 0.63999005 - samples/sec: 40.41\n",
      "2019-10-25 07:18:51,106 epoch 47 - iter 4/24 - loss 0.65092351 - samples/sec: 41.68\n",
      "2019-10-25 07:18:52,902 epoch 47 - iter 6/24 - loss 0.74562763 - samples/sec: 36.84\n",
      "2019-10-25 07:18:54,710 epoch 47 - iter 8/24 - loss 0.75760606 - samples/sec: 36.43\n",
      "2019-10-25 07:18:56,599 epoch 47 - iter 10/24 - loss 0.73383020 - samples/sec: 35.15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:18:58,276 epoch 47 - iter 12/24 - loss 0.70568141 - samples/sec: 39.51\n",
      "2019-10-25 07:19:00,107 epoch 47 - iter 14/24 - loss 0.70317826 - samples/sec: 35.98\n",
      "2019-10-25 07:19:01,809 epoch 47 - iter 16/24 - loss 0.69112670 - samples/sec: 39.02\n",
      "2019-10-25 07:19:03,648 epoch 47 - iter 18/24 - loss 0.67279014 - samples/sec: 35.93\n",
      "2019-10-25 07:19:05,795 epoch 47 - iter 20/24 - loss 0.66075538 - samples/sec: 30.62\n",
      "2019-10-25 07:19:07,575 epoch 47 - iter 22/24 - loss 0.66707240 - samples/sec: 37.56\n",
      "2019-10-25 07:19:08,736 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:19:08,737 EPOCH 47 done: loss 0.6761 - lr 0.0500\n",
      "2019-10-25 07:19:20,288 DEV : loss 1.1154601573944092 - score 0.5427\n",
      "2019-10-25 07:19:20,408 BAD EPOCHS (no improvement): 4\n",
      "2019-10-25 07:19:20,410 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:19:32,086 epoch 48 - iter 0/24 - loss 1.03286731 - samples/sec: 72.59\n",
      "2019-10-25 07:19:34,026 epoch 48 - iter 2/24 - loss 0.87247145 - samples/sec: 34.11\n",
      "2019-10-25 07:19:36,032 epoch 48 - iter 4/24 - loss 0.79703070 - samples/sec: 32.75\n",
      "2019-10-25 07:19:37,615 epoch 48 - iter 6/24 - loss 0.77677864 - samples/sec: 42.25\n",
      "2019-10-25 07:19:39,217 epoch 48 - iter 8/24 - loss 0.79580176 - samples/sec: 41.71\n",
      "2019-10-25 07:19:41,062 epoch 48 - iter 10/24 - loss 0.76649626 - samples/sec: 35.53\n",
      "2019-10-25 07:19:42,867 epoch 48 - iter 12/24 - loss 0.75015950 - samples/sec: 36.55\n",
      "2019-10-25 07:19:44,561 epoch 48 - iter 14/24 - loss 0.74730915 - samples/sec: 39.37\n",
      "2019-10-25 07:19:46,417 epoch 48 - iter 16/24 - loss 0.76116597 - samples/sec: 35.30\n",
      "2019-10-25 07:19:48,477 epoch 48 - iter 18/24 - loss 0.75105202 - samples/sec: 41.51\n",
      "2019-10-25 07:19:50,236 epoch 48 - iter 20/24 - loss 0.73927333 - samples/sec: 37.82\n",
      "2019-10-25 07:19:51,946 epoch 48 - iter 22/24 - loss 0.75108526 - samples/sec: 38.38\n",
      "2019-10-25 07:19:52,981 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:19:52,982 EPOCH 48 done: loss 0.7640 - lr 0.0500\n",
      "2019-10-25 07:20:04,586 DEV : loss 0.8836772441864014 - score 0.5854\n",
      "2019-10-25 07:20:04,706 BAD EPOCHS (no improvement): 5\n",
      "2019-10-25 07:20:04,708 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:20:16,329 epoch 49 - iter 0/24 - loss 0.72030866 - samples/sec: 74.31\n",
      "2019-10-25 07:20:17,939 epoch 49 - iter 2/24 - loss 0.68212396 - samples/sec: 40.96\n",
      "2019-10-25 07:20:19,880 epoch 49 - iter 4/24 - loss 0.69727026 - samples/sec: 34.10\n",
      "2019-10-25 07:20:21,659 epoch 49 - iter 6/24 - loss 0.63098697 - samples/sec: 37.51\n",
      "2019-10-25 07:20:23,490 epoch 49 - iter 8/24 - loss 0.73141875 - samples/sec: 35.79\n",
      "2019-10-25 07:20:25,241 epoch 49 - iter 10/24 - loss 0.71874403 - samples/sec: 38.00\n",
      "2019-10-25 07:20:26,936 epoch 49 - iter 12/24 - loss 0.70619251 - samples/sec: 39.70\n",
      "2019-10-25 07:20:28,736 epoch 49 - iter 14/24 - loss 0.71904109 - samples/sec: 36.45\n",
      "2019-10-25 07:20:30,360 epoch 49 - iter 16/24 - loss 0.71946969 - samples/sec: 40.86\n",
      "2019-10-25 07:20:32,084 epoch 49 - iter 18/24 - loss 0.71260997 - samples/sec: 38.55\n",
      "2019-10-25 07:20:33,906 epoch 49 - iter 20/24 - loss 0.68658441 - samples/sec: 36.02\n",
      "2019-10-25 07:20:35,906 epoch 49 - iter 22/24 - loss 0.66685847 - samples/sec: 33.29\n",
      "2019-10-25 07:20:37,072 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:20:37,073 EPOCH 49 done: loss 0.6694 - lr 0.0500\n",
      "2019-10-25 07:20:48,710 DEV : loss 1.0330718755722046 - score 0.5915\n",
      "Epoch    48: reducing learning rate of group 0 to 2.5000e-02.\n",
      "2019-10-25 07:20:48,826 BAD EPOCHS (no improvement): 6\n",
      "2019-10-25 07:20:48,828 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:21:01,655 epoch 50 - iter 0/24 - loss 1.00184727 - samples/sec: 64.64\n",
      "2019-10-25 07:21:03,648 epoch 50 - iter 2/24 - loss 0.66860949 - samples/sec: 33.65\n",
      "2019-10-25 07:21:05,647 epoch 50 - iter 4/24 - loss 0.59542846 - samples/sec: 32.93\n",
      "2019-10-25 07:21:07,561 epoch 50 - iter 6/24 - loss 0.59856620 - samples/sec: 34.72\n",
      "2019-10-25 07:21:09,255 epoch 50 - iter 8/24 - loss 0.57207525 - samples/sec: 39.04\n",
      "2019-10-25 07:21:11,013 epoch 50 - iter 10/24 - loss 0.53890940 - samples/sec: 37.46\n",
      "2019-10-25 07:21:12,895 epoch 50 - iter 12/24 - loss 0.57054827 - samples/sec: 35.15\n",
      "2019-10-25 07:21:14,708 epoch 50 - iter 14/24 - loss 0.58168240 - samples/sec: 36.48\n",
      "2019-10-25 07:21:16,659 epoch 50 - iter 16/24 - loss 0.56600277 - samples/sec: 33.72\n",
      "2019-10-25 07:21:18,851 epoch 50 - iter 18/24 - loss 0.57053616 - samples/sec: 38.35\n",
      "2019-10-25 07:21:20,642 epoch 50 - iter 20/24 - loss 0.57494190 - samples/sec: 36.88\n",
      "2019-10-25 07:21:22,444 epoch 50 - iter 22/24 - loss 0.58029007 - samples/sec: 36.52\n",
      "2019-10-25 07:21:23,593 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:21:23,595 EPOCH 50 done: loss 0.5870 - lr 0.0250\n",
      "2019-10-25 07:21:35,151 DEV : loss 0.7975430488586426 - score 0.6646\n",
      "2019-10-25 07:21:35,285 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:21:38,091 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:21:50,036 epoch 51 - iter 0/24 - loss 0.80771333 - samples/sec: 88.85\n",
      "2019-10-25 07:21:51,939 epoch 51 - iter 2/24 - loss 0.61829492 - samples/sec: 34.85\n",
      "2019-10-25 07:21:53,610 epoch 51 - iter 4/24 - loss 0.56804599 - samples/sec: 39.46\n",
      "2019-10-25 07:21:55,541 epoch 51 - iter 6/24 - loss 0.55318558 - samples/sec: 34.56\n",
      "2019-10-25 07:21:57,376 epoch 51 - iter 8/24 - loss 0.55577687 - samples/sec: 36.21\n",
      "2019-10-25 07:21:59,049 epoch 51 - iter 10/24 - loss 0.54424957 - samples/sec: 39.30\n",
      "2019-10-25 07:22:00,840 epoch 51 - iter 12/24 - loss 0.53539208 - samples/sec: 37.10\n",
      "2019-10-25 07:22:02,485 epoch 51 - iter 14/24 - loss 0.54723276 - samples/sec: 40.51\n",
      "2019-10-25 07:22:04,557 epoch 51 - iter 16/24 - loss 0.56374357 - samples/sec: 31.57\n",
      "2019-10-25 07:22:06,644 epoch 51 - iter 18/24 - loss 0.56205882 - samples/sec: 31.65\n",
      "2019-10-25 07:22:08,323 epoch 51 - iter 20/24 - loss 0.56376401 - samples/sec: 39.61\n",
      "2019-10-25 07:22:09,896 epoch 51 - iter 22/24 - loss 0.56666775 - samples/sec: 41.85\n",
      "2019-10-25 07:22:10,955 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:22:10,956 EPOCH 51 done: loss 0.5756 - lr 0.0250\n",
      "2019-10-25 07:22:22,534 DEV : loss 0.794891893863678 - score 0.628\n",
      "2019-10-25 07:22:22,653 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:22:22,655 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:22:35,787 epoch 52 - iter 0/24 - loss 0.66807604 - samples/sec: 69.32\n",
      "2019-10-25 07:22:37,796 epoch 52 - iter 2/24 - loss 0.53988124 - samples/sec: 33.62\n",
      "2019-10-25 07:22:39,553 epoch 52 - iter 4/24 - loss 0.50736532 - samples/sec: 37.46\n",
      "2019-10-25 07:22:41,621 epoch 52 - iter 6/24 - loss 0.49769653 - samples/sec: 31.91\n",
      "2019-10-25 07:22:43,622 epoch 52 - iter 8/24 - loss 0.52179112 - samples/sec: 33.55\n",
      "2019-10-25 07:22:45,609 epoch 52 - iter 10/24 - loss 0.53168687 - samples/sec: 33.92\n",
      "2019-10-25 07:22:47,527 epoch 52 - iter 12/24 - loss 0.57116707 - samples/sec: 34.60\n",
      "2019-10-25 07:22:49,992 epoch 52 - iter 14/24 - loss 0.56465256 - samples/sec: 33.30\n",
      "2019-10-25 07:22:52,305 epoch 52 - iter 16/24 - loss 0.56564610 - samples/sec: 28.32\n",
      "2019-10-25 07:22:54,541 epoch 52 - iter 18/24 - loss 0.55603780 - samples/sec: 29.60\n",
      "2019-10-25 07:22:56,442 epoch 52 - iter 20/24 - loss 0.56987210 - samples/sec: 34.92\n",
      "2019-10-25 07:22:58,155 epoch 52 - iter 22/24 - loss 0.56528218 - samples/sec: 38.30\n",
      "2019-10-25 07:22:59,310 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:22:59,311 EPOCH 52 done: loss 0.5551 - lr 0.0250\n",
      "2019-10-25 07:23:11,294 DEV : loss 0.9436938166618347 - score 0.5976\n",
      "2019-10-25 07:23:11,403 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:23:11,405 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:23:24,102 epoch 53 - iter 0/24 - loss 0.43452036 - samples/sec: 56.74\n",
      "2019-10-25 07:23:26,304 epoch 53 - iter 2/24 - loss 0.51420826 - samples/sec: 29.85\n",
      "2019-10-25 07:23:28,522 epoch 53 - iter 4/24 - loss 0.57091818 - samples/sec: 29.56\n",
      "2019-10-25 07:23:30,633 epoch 53 - iter 6/24 - loss 0.54612073 - samples/sec: 31.56\n",
      "2019-10-25 07:23:32,519 epoch 53 - iter 8/24 - loss 0.56167242 - samples/sec: 34.77\n",
      "2019-10-25 07:23:34,302 epoch 53 - iter 10/24 - loss 0.58181300 - samples/sec: 36.72\n",
      "2019-10-25 07:23:36,490 epoch 53 - iter 12/24 - loss 0.58255421 - samples/sec: 30.68\n",
      "2019-10-25 07:23:38,437 epoch 53 - iter 14/24 - loss 0.58018672 - samples/sec: 33.69\n",
      "2019-10-25 07:23:40,076 epoch 53 - iter 16/24 - loss 0.57383733 - samples/sec: 40.01\n",
      "2019-10-25 07:23:41,808 epoch 53 - iter 18/24 - loss 0.56938091 - samples/sec: 38.56\n",
      "2019-10-25 07:23:43,618 epoch 53 - iter 20/24 - loss 0.56099905 - samples/sec: 36.16\n",
      "2019-10-25 07:23:45,563 epoch 53 - iter 22/24 - loss 0.55643257 - samples/sec: 33.80\n",
      "2019-10-25 07:23:46,981 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:23:46,982 EPOCH 53 done: loss 0.5550 - lr 0.0250\n",
      "2019-10-25 07:23:59,077 DEV : loss 0.7820841670036316 - score 0.6707\n",
      "2019-10-25 07:23:59,185 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:24:02,071 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:24:15,050 epoch 54 - iter 0/24 - loss 0.33222514 - samples/sec: 64.04\n",
      "2019-10-25 07:24:17,245 epoch 54 - iter 2/24 - loss 0.40659412 - samples/sec: 30.12\n",
      "2019-10-25 07:24:18,945 epoch 54 - iter 4/24 - loss 0.38457347 - samples/sec: 38.59\n",
      "2019-10-25 07:24:20,739 epoch 54 - iter 6/24 - loss 0.45924517 - samples/sec: 36.54\n",
      "2019-10-25 07:24:22,968 epoch 54 - iter 8/24 - loss 0.49164095 - samples/sec: 37.59\n",
      "2019-10-25 07:24:24,913 epoch 54 - iter 10/24 - loss 0.50722410 - samples/sec: 33.61\n",
      "2019-10-25 07:24:26,664 epoch 54 - iter 12/24 - loss 0.54175110 - samples/sec: 37.50\n",
      "2019-10-25 07:24:28,456 epoch 54 - iter 14/24 - loss 0.54998570 - samples/sec: 37.31\n",
      "2019-10-25 07:24:30,208 epoch 54 - iter 16/24 - loss 0.55090473 - samples/sec: 37.45\n",
      "2019-10-25 07:24:31,984 epoch 54 - iter 18/24 - loss 0.57940716 - samples/sec: 36.88\n",
      "2019-10-25 07:24:33,543 epoch 54 - iter 20/24 - loss 0.58702932 - samples/sec: 42.96\n",
      "2019-10-25 07:24:35,252 epoch 54 - iter 22/24 - loss 0.59800470 - samples/sec: 38.40\n",
      "2019-10-25 07:24:36,555 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:24:36,596 EPOCH 54 done: loss 0.5932 - lr 0.0250\n",
      "2019-10-25 07:24:48,709 DEV : loss 0.8219465613365173 - score 0.628\n",
      "2019-10-25 07:24:48,833 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:24:48,879 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:25:01,333 epoch 55 - iter 0/24 - loss 0.54752678 - samples/sec: 65.37\n",
      "2019-10-25 07:25:03,266 epoch 55 - iter 2/24 - loss 0.59272176 - samples/sec: 34.21\n",
      "2019-10-25 07:25:05,206 epoch 55 - iter 4/24 - loss 0.58031802 - samples/sec: 33.77\n",
      "2019-10-25 07:25:06,976 epoch 55 - iter 6/24 - loss 0.56541250 - samples/sec: 37.62\n",
      "2019-10-25 07:25:08,746 epoch 55 - iter 8/24 - loss 0.57540368 - samples/sec: 37.45\n",
      "2019-10-25 07:25:10,259 epoch 55 - iter 10/24 - loss 0.56660617 - samples/sec: 43.44\n",
      "2019-10-25 07:25:11,821 epoch 55 - iter 12/24 - loss 0.55828365 - samples/sec: 42.62\n",
      "2019-10-25 07:25:13,555 epoch 55 - iter 14/24 - loss 0.56145907 - samples/sec: 38.22\n",
      "2019-10-25 07:25:15,281 epoch 55 - iter 16/24 - loss 0.54333646 - samples/sec: 38.08\n",
      "2019-10-25 07:25:17,264 epoch 55 - iter 18/24 - loss 0.53815923 - samples/sec: 33.41\n",
      "2019-10-25 07:25:19,007 epoch 55 - iter 20/24 - loss 0.55814230 - samples/sec: 37.95\n",
      "2019-10-25 07:25:20,492 epoch 55 - iter 22/24 - loss 0.55597587 - samples/sec: 44.32\n",
      "2019-10-25 07:25:21,566 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:25:21,568 EPOCH 55 done: loss 0.5513 - lr 0.0250\n",
      "2019-10-25 07:25:33,459 DEV : loss 0.7890233993530273 - score 0.6585\n",
      "2019-10-25 07:25:33,587 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:25:33,589 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:25:46,210 epoch 56 - iter 0/24 - loss 0.48240694 - samples/sec: 73.71\n",
      "2019-10-25 07:25:48,077 epoch 56 - iter 2/24 - loss 0.45480549 - samples/sec: 35.32\n",
      "2019-10-25 07:25:50,327 epoch 56 - iter 4/24 - loss 0.51543930 - samples/sec: 36.40\n",
      "2019-10-25 07:25:52,133 epoch 56 - iter 6/24 - loss 0.55260877 - samples/sec: 36.51\n",
      "2019-10-25 07:25:53,956 epoch 56 - iter 8/24 - loss 0.52793391 - samples/sec: 36.14\n",
      "2019-10-25 07:25:55,829 epoch 56 - iter 10/24 - loss 0.52281735 - samples/sec: 35.32\n",
      "2019-10-25 07:25:57,460 epoch 56 - iter 12/24 - loss 0.52466340 - samples/sec: 40.75\n",
      "2019-10-25 07:25:59,079 epoch 56 - iter 14/24 - loss 0.53155708 - samples/sec: 40.93\n",
      "2019-10-25 07:26:00,742 epoch 56 - iter 16/24 - loss 0.53862757 - samples/sec: 39.73\n",
      "2019-10-25 07:26:02,610 epoch 56 - iter 18/24 - loss 0.53424221 - samples/sec: 35.28\n",
      "2019-10-25 07:26:04,789 epoch 56 - iter 20/24 - loss 0.53538285 - samples/sec: 30.12\n",
      "2019-10-25 07:26:06,818 epoch 56 - iter 22/24 - loss 0.54834316 - samples/sec: 32.49\n",
      "2019-10-25 07:26:07,952 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:26:07,953 EPOCH 56 done: loss 0.5502 - lr 0.0250\n",
      "2019-10-25 07:26:19,908 DEV : loss 0.8198280334472656 - score 0.6402\n",
      "2019-10-25 07:26:20,080 BAD EPOCHS (no improvement): 3\n",
      "2019-10-25 07:26:20,082 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:26:31,721 epoch 57 - iter 0/24 - loss 0.47702837 - samples/sec: 82.20\n",
      "2019-10-25 07:26:33,606 epoch 57 - iter 2/24 - loss 0.48230904 - samples/sec: 34.98\n",
      "2019-10-25 07:26:35,344 epoch 57 - iter 4/24 - loss 0.53014028 - samples/sec: 37.91\n",
      "2019-10-25 07:26:37,128 epoch 57 - iter 6/24 - loss 0.46811387 - samples/sec: 37.31\n",
      "2019-10-25 07:26:38,754 epoch 57 - iter 8/24 - loss 0.50070554 - samples/sec: 40.87\n",
      "2019-10-25 07:26:40,616 epoch 57 - iter 10/24 - loss 0.47764606 - samples/sec: 35.09\n",
      "2019-10-25 07:26:42,368 epoch 57 - iter 12/24 - loss 0.52634641 - samples/sec: 37.86\n",
      "2019-10-25 07:26:44,507 epoch 57 - iter 14/24 - loss 0.53329989 - samples/sec: 31.00\n",
      "2019-10-25 07:26:46,855 epoch 57 - iter 16/24 - loss 0.55452657 - samples/sec: 28.46\n",
      "2019-10-25 07:26:48,624 epoch 57 - iter 18/24 - loss 0.55136878 - samples/sec: 37.62\n",
      "2019-10-25 07:26:50,424 epoch 57 - iter 20/24 - loss 0.54924412 - samples/sec: 36.78\n",
      "2019-10-25 07:26:52,324 epoch 57 - iter 22/24 - loss 0.54745800 - samples/sec: 34.46\n",
      "2019-10-25 07:26:53,500 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:26:53,502 EPOCH 57 done: loss 0.5603 - lr 0.0250\n",
      "2019-10-25 07:27:05,860 DEV : loss 0.8944259285926819 - score 0.6037\n",
      "2019-10-25 07:27:05,992 BAD EPOCHS (no improvement): 4\n",
      "2019-10-25 07:27:05,995 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:27:18,475 epoch 58 - iter 0/24 - loss 0.49819362 - samples/sec: 72.03\n",
      "2019-10-25 07:27:20,292 epoch 58 - iter 2/24 - loss 0.53860615 - samples/sec: 36.55\n",
      "2019-10-25 07:27:21,939 epoch 58 - iter 4/24 - loss 0.50662196 - samples/sec: 39.84\n",
      "2019-10-25 07:27:23,694 epoch 58 - iter 6/24 - loss 0.48810597 - samples/sec: 37.97\n",
      "2019-10-25 07:27:25,470 epoch 58 - iter 8/24 - loss 0.51518417 - samples/sec: 37.67\n",
      "2019-10-25 07:27:27,368 epoch 58 - iter 10/24 - loss 0.51631146 - samples/sec: 34.54\n",
      "2019-10-25 07:27:29,096 epoch 58 - iter 12/24 - loss 0.51646669 - samples/sec: 38.30\n",
      "2019-10-25 07:27:31,002 epoch 58 - iter 14/24 - loss 0.50141728 - samples/sec: 34.84\n",
      "2019-10-25 07:27:32,840 epoch 58 - iter 16/24 - loss 0.52899077 - samples/sec: 35.82\n",
      "2019-10-25 07:27:34,615 epoch 58 - iter 18/24 - loss 0.54827049 - samples/sec: 37.28\n",
      "2019-10-25 07:27:36,507 epoch 58 - iter 20/24 - loss 0.54454297 - samples/sec: 35.05\n",
      "2019-10-25 07:27:38,212 epoch 58 - iter 22/24 - loss 0.55033582 - samples/sec: 38.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:27:39,578 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:27:39,580 EPOCH 58 done: loss 0.5559 - lr 0.0250\n",
      "2019-10-25 07:27:51,675 DEV : loss 0.8297656178474426 - score 0.622\n",
      "2019-10-25 07:27:51,787 BAD EPOCHS (no improvement): 5\n",
      "2019-10-25 07:27:51,788 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:28:03,734 epoch 59 - iter 0/24 - loss 0.43595353 - samples/sec: 74.36\n",
      "2019-10-25 07:28:05,582 epoch 59 - iter 2/24 - loss 0.44809424 - samples/sec: 35.94\n",
      "2019-10-25 07:28:07,382 epoch 59 - iter 4/24 - loss 0.44702618 - samples/sec: 36.57\n",
      "2019-10-25 07:28:09,465 epoch 59 - iter 6/24 - loss 0.43417579 - samples/sec: 31.71\n",
      "2019-10-25 07:28:11,277 epoch 59 - iter 8/24 - loss 0.46022122 - samples/sec: 36.59\n",
      "2019-10-25 07:28:13,043 epoch 59 - iter 10/24 - loss 0.46588650 - samples/sec: 37.17\n",
      "2019-10-25 07:28:15,104 epoch 59 - iter 12/24 - loss 0.48497264 - samples/sec: 32.08\n",
      "2019-10-25 07:28:16,902 epoch 59 - iter 14/24 - loss 0.50880614 - samples/sec: 36.99\n",
      "2019-10-25 07:28:18,681 epoch 59 - iter 16/24 - loss 0.53141672 - samples/sec: 36.85\n",
      "2019-10-25 07:28:20,246 epoch 59 - iter 18/24 - loss 0.54058301 - samples/sec: 42.53\n",
      "2019-10-25 07:28:22,163 epoch 59 - iter 20/24 - loss 0.52845547 - samples/sec: 34.52\n",
      "2019-10-25 07:28:24,031 epoch 59 - iter 22/24 - loss 0.52952945 - samples/sec: 35.03\n",
      "2019-10-25 07:28:25,218 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:28:25,220 EPOCH 59 done: loss 0.5219 - lr 0.0250\n",
      "2019-10-25 07:28:37,481 DEV : loss 0.7890525460243225 - score 0.628\n",
      "Epoch    58: reducing learning rate of group 0 to 1.2500e-02.\n",
      "2019-10-25 07:28:37,591 BAD EPOCHS (no improvement): 6\n",
      "2019-10-25 07:28:37,593 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:28:49,150 epoch 60 - iter 0/24 - loss 0.30063063 - samples/sec: 78.21\n",
      "2019-10-25 07:28:50,903 epoch 60 - iter 2/24 - loss 0.41733669 - samples/sec: 37.40\n",
      "2019-10-25 07:28:52,850 epoch 60 - iter 4/24 - loss 0.48264534 - samples/sec: 34.71\n",
      "2019-10-25 07:28:54,794 epoch 60 - iter 6/24 - loss 0.47587920 - samples/sec: 34.51\n",
      "2019-10-25 07:28:57,062 epoch 60 - iter 8/24 - loss 0.46935139 - samples/sec: 28.81\n",
      "2019-10-25 07:28:59,177 epoch 60 - iter 10/24 - loss 0.48914707 - samples/sec: 30.85\n",
      "2019-10-25 07:29:01,118 epoch 60 - iter 12/24 - loss 0.51254642 - samples/sec: 34.93\n",
      "2019-10-25 07:29:03,341 epoch 60 - iter 14/24 - loss 0.51954239 - samples/sec: 29.83\n",
      "2019-10-25 07:29:05,215 epoch 60 - iter 16/24 - loss 0.52001128 - samples/sec: 35.04\n",
      "2019-10-25 07:29:06,962 epoch 60 - iter 18/24 - loss 0.50450678 - samples/sec: 38.63\n",
      "2019-10-25 07:29:08,767 epoch 60 - iter 20/24 - loss 0.49464538 - samples/sec: 36.30\n",
      "2019-10-25 07:29:10,414 epoch 60 - iter 22/24 - loss 0.49780826 - samples/sec: 39.85\n",
      "2019-10-25 07:29:11,530 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:29:11,531 EPOCH 60 done: loss 0.4932 - lr 0.0125\n",
      "2019-10-25 07:29:23,100 DEV : loss 0.8208127617835999 - score 0.6524\n",
      "2019-10-25 07:29:23,214 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:29:23,216 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:29:34,806 epoch 61 - iter 0/24 - loss 0.48991707 - samples/sec: 90.11\n",
      "2019-10-25 07:29:36,901 epoch 61 - iter 2/24 - loss 0.40344560 - samples/sec: 31.47\n",
      "2019-10-25 07:29:38,607 epoch 61 - iter 4/24 - loss 0.53482995 - samples/sec: 38.60\n",
      "2019-10-25 07:29:40,361 epoch 61 - iter 6/24 - loss 0.50474624 - samples/sec: 37.68\n",
      "2019-10-25 07:29:42,071 epoch 61 - iter 8/24 - loss 0.46385152 - samples/sec: 38.70\n",
      "2019-10-25 07:29:43,864 epoch 61 - iter 10/24 - loss 0.47444426 - samples/sec: 36.66\n",
      "2019-10-25 07:29:45,637 epoch 61 - iter 12/24 - loss 0.47609843 - samples/sec: 37.42\n",
      "2019-10-25 07:29:47,431 epoch 61 - iter 14/24 - loss 0.49991365 - samples/sec: 37.03\n",
      "2019-10-25 07:29:49,242 epoch 61 - iter 16/24 - loss 0.50213969 - samples/sec: 36.27\n",
      "2019-10-25 07:29:51,093 epoch 61 - iter 18/24 - loss 0.50326172 - samples/sec: 35.62\n",
      "2019-10-25 07:29:53,200 epoch 61 - iter 20/24 - loss 0.50999522 - samples/sec: 39.97\n",
      "2019-10-25 07:29:55,162 epoch 61 - iter 22/24 - loss 0.50106269 - samples/sec: 34.37\n",
      "2019-10-25 07:29:56,481 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:29:56,482 EPOCH 61 done: loss 0.5053 - lr 0.0125\n",
      "2019-10-25 07:30:07,931 DEV : loss 0.7675572037696838 - score 0.6402\n",
      "2019-10-25 07:30:08,043 BAD EPOCHS (no improvement): 2\n",
      "2019-10-25 07:30:08,045 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:30:20,636 epoch 62 - iter 0/24 - loss 0.60149765 - samples/sec: 51.40\n",
      "2019-10-25 07:30:22,322 epoch 62 - iter 2/24 - loss 0.60844896 - samples/sec: 39.05\n",
      "2019-10-25 07:30:24,393 epoch 62 - iter 4/24 - loss 0.53812063 - samples/sec: 31.64\n",
      "2019-10-25 07:30:26,482 epoch 62 - iter 6/24 - loss 0.49500546 - samples/sec: 31.72\n",
      "2019-10-25 07:30:28,153 epoch 62 - iter 8/24 - loss 0.48148561 - samples/sec: 39.25\n",
      "2019-10-25 07:30:29,817 epoch 62 - iter 10/24 - loss 0.48838106 - samples/sec: 39.54\n",
      "2019-10-25 07:30:31,344 epoch 62 - iter 12/24 - loss 0.50277472 - samples/sec: 43.98\n",
      "2019-10-25 07:30:33,125 epoch 62 - iter 14/24 - loss 0.51771118 - samples/sec: 36.76\n",
      "2019-10-25 07:30:34,998 epoch 62 - iter 16/24 - loss 0.50431086 - samples/sec: 35.08\n",
      "2019-10-25 07:30:36,856 epoch 62 - iter 18/24 - loss 0.49653519 - samples/sec: 35.87\n",
      "2019-10-25 07:30:38,633 epoch 62 - iter 20/24 - loss 0.49217079 - samples/sec: 36.92\n",
      "2019-10-25 07:30:40,386 epoch 62 - iter 22/24 - loss 0.49132894 - samples/sec: 37.43\n",
      "2019-10-25 07:30:41,614 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:30:41,615 EPOCH 62 done: loss 0.4806 - lr 0.0125\n",
      "2019-10-25 07:30:53,370 DEV : loss 0.778062641620636 - score 0.6768\n",
      "2019-10-25 07:30:53,495 BAD EPOCHS (no improvement): 0\n",
      "2019-10-25 07:30:56,540 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:31:08,746 epoch 63 - iter 0/24 - loss 0.62961316 - samples/sec: 71.86\n",
      "2019-10-25 07:31:11,027 epoch 63 - iter 2/24 - loss 0.53714227 - samples/sec: 28.56\n",
      "2019-10-25 07:31:13,038 epoch 63 - iter 4/24 - loss 0.52500759 - samples/sec: 32.84\n",
      "2019-10-25 07:31:14,921 epoch 63 - iter 6/24 - loss 0.57029754 - samples/sec: 35.56\n",
      "2019-10-25 07:31:16,983 epoch 63 - iter 8/24 - loss 0.54095088 - samples/sec: 31.99\n",
      "2019-10-25 07:31:18,900 epoch 63 - iter 10/24 - loss 0.53481752 - samples/sec: 34.44\n",
      "2019-10-25 07:31:20,943 epoch 63 - iter 12/24 - loss 0.51769967 - samples/sec: 32.37\n",
      "2019-10-25 07:31:22,818 epoch 63 - iter 14/24 - loss 0.50587050 - samples/sec: 35.11\n",
      "2019-10-25 07:31:24,682 epoch 63 - iter 16/24 - loss 0.49536723 - samples/sec: 35.35\n",
      "2019-10-25 07:31:26,502 epoch 63 - iter 18/24 - loss 0.48714983 - samples/sec: 36.37\n",
      "2019-10-25 07:31:28,479 epoch 63 - iter 20/24 - loss 0.49797188 - samples/sec: 43.73\n",
      "2019-10-25 07:31:30,289 epoch 63 - iter 22/24 - loss 0.49283296 - samples/sec: 36.43\n",
      "2019-10-25 07:31:31,534 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:31:31,535 EPOCH 63 done: loss 0.5117 - lr 0.0125\n",
      "2019-10-25 07:31:43,511 DEV : loss 0.7610394358634949 - score 0.6646\n",
      "2019-10-25 07:31:43,651 BAD EPOCHS (no improvement): 1\n",
      "2019-10-25 07:31:43,653 ----------------------------------------------------------------------------------------------------\n",
      "2019-10-25 07:31:55,335 epoch 64 - iter 0/24 - loss 0.48499143 - samples/sec: 81.29\n",
      "2019-10-25 07:31:57,097 epoch 64 - iter 2/24 - loss 0.47357832 - samples/sec: 37.68\n",
      "2019-10-25 07:31:58,954 epoch 64 - iter 4/24 - loss 0.47118542 - samples/sec: 36.22\n",
      "2019-10-25 07:32:00,799 epoch 64 - iter 6/24 - loss 0.49880614 - samples/sec: 35.80\n",
      "2019-10-25 07:32:02,592 epoch 64 - iter 8/24 - loss 0.53023493 - samples/sec: 37.00\n",
      "2019-10-25 07:32:04,694 epoch 64 - iter 10/24 - loss 0.51905962 - samples/sec: 31.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-25 07:32:06,694 epoch 64 - iter 12/24 - loss 0.50810600 - samples/sec: 33.00\n",
      "2019-10-25 07:32:08,442 epoch 64 - iter 14/24 - loss 0.50678663 - samples/sec: 37.95\n",
      "2019-10-25 07:32:10,323 epoch 64 - iter 16/24 - loss 0.48886657 - samples/sec: 35.03\n",
      "2019-10-25 07:32:12,138 epoch 64 - iter 18/24 - loss 0.48734082 - samples/sec: 36.40\n"
     ]
    }
   ],
   "source": [
    "# 6. initialize the text classifier trainer\n",
    "trainer = ModelTrainer(classifier, corpus)\n",
    "\n",
    "# 7. start the training\n",
    "trainer.train('data/',\n",
    "              learning_rate=0.1,\n",
    "              mini_batch_size=32,\n",
    "              anneal_factor=0.5,\n",
    "              patience=5,\n",
    "              max_epochs=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. plot weight traces (optional)\n",
    "from flair.visual.training_curves import Plotter\n",
    "plotter = Plotter()\n",
    "plotter.plot_weights('data/weights.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contextual Word Vectors with BERT and Stacking Embeddings\n",
    "We will later use BERT, a state-of-the-art transformer model that was trained on a very large corpus and can be fine-tuned for our own custom task. The Flair package can also be used to derive contextual word embeddings using BERT and its successors. We will use a different package for BERT, to provide you with sample code for using it, and for adaptation of the weights of the BERT model itself for our own task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, you can try to use BERT, Roberta, XLNet or other models provided in Flair for contextual word embeddings.  \n",
    "Flair also provides a simple way to stack vectors from different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-17 08:38:42,789 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/lm-multi-forward-v0.1.pt not found in cache, downloading to C:\\Users\\Omri\\AppData\\Local\\Temp\\tmppppabpwb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 73034300/73034300 [00:08<00:00, 8530759.25B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-17 08:38:51,700 copying C:\\Users\\Omri\\AppData\\Local\\Temp\\tmppppabpwb to cache at C:\\Users\\Omri\\.flair\\embeddings\\lm-multi-forward-v0.1.pt\n",
      "2019-10-17 08:38:51,779 removing temp file C:\\Users\\Omri\\AppData\\Local\\Temp\\tmppppabpwb\n",
      "2019-10-17 08:38:52,276 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4/lm-multi-backward-v0.1.pt not found in cache, downloading to C:\\Users\\Omri\\AppData\\Local\\Temp\\tmptvnijhdp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████| 73034304/73034304 [00:12<00:00, 5879942.68B/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-10-17 08:39:05,094 copying C:\\Users\\Omri\\AppData\\Local\\Temp\\tmptvnijhdp to cache at C:\\Users\\Omri\\.flair\\embeddings\\lm-multi-backward-v0.1.pt\n",
      "2019-10-17 08:39:05,172 removing temp file C:\\Users\\Omri\\AppData\\Local\\Temp\\tmptvnijhdp\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 995526/995526 [00:00<00:00, 1143581.85B/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 521/521 [00:00<00:00, 262364.32B/s]\n",
      "100%|███████████████████████████████████████████████████████████████| 714314041/714314041 [01:08<00:00, 10488502.38B/s]\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import FlairEmbeddings, BertEmbeddings\n",
    "\n",
    "# init Flair embeddings\n",
    "flair_forward_embedding = FlairEmbeddings('multi-forward')\n",
    "flair_backward_embedding = FlairEmbeddings('multi-backward')\n",
    "\n",
    "# init BERT\n",
    "bert_embedding = BertEmbeddings('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, DocumentPoolEmbeddings, Sentence\n",
    "from flair.embeddings import StackedEmbeddings\n",
    "\n",
    "# now create the StackedEmbedding object that combines all embeddings\n",
    "stacked_embeddings = StackedEmbeddings(\n",
    "    embeddings=[flair_forward_embedding, flair_backward_embedding, bert_embedding])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token: 1 The\n",
      "tensor([-1.4812e-07,  4.5007e-08,  6.0273e-07,  ...,  3.8287e-01,\n",
      "         4.7210e-01,  2.9850e-01])\n",
      "Token: 2 grass\n",
      "tensor([ 1.6254e-04,  1.8764e-07, -7.9038e-09,  ...,  8.5283e-01,\n",
      "        -5.0726e-02,  3.4476e-01])\n",
      "Token: 3 is\n",
      "tensor([-2.4521e-04,  3.4869e-07,  5.5841e-06,  ..., -1.8283e-01,\n",
      "         7.1532e-01,  5.0841e-03])\n",
      "Token: 4 green\n",
      "tensor([8.3005e-05, 4.7261e-08, 5.7315e-07,  ..., 1.0157e+00, 7.5358e-01,\n",
      "        1.1230e-01])\n",
      "Token: 5 .\n",
      "tensor([-8.3244e-07,  1.6451e-07, -1.7201e-08,  ..., -6.0930e-01,\n",
      "         9.0591e-01,  1.7857e-01])\n"
     ]
    }
   ],
   "source": [
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "# just embed a sentence using the StackedEmbedding as you would with any single embedding.\n",
    "stacked_embeddings.embed(sentence)\n",
    "\n",
    "# now check out the embedded tokens.\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it yourself:** Train a classifier using stacked embeddings of different models. Do you see an increase in performance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
