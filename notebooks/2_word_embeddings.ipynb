{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/omriallouche/text_classification_from_zero_to_hero.git --depth 1\n",
    "import os\n",
    "os.chdir('text_classification_from_zero_to_hero/notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec, GloVe and Word Embeddings\n",
    "## Part 2 of the Workshop \"Text Classification - From Zero to Hero\", by Dr. Omri Allouche, Gong.io, Bar Ilan University\n",
    "\n",
    "For this presentation, we will use FLAIR: https://www.analyticsvidhya.com/blog/2019/02/flair-nlp-library-python/?utm_source=blog&utm_medium=top-pretrained-models-nlp-article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: gensim in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.16.2)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.2.1)\n",
      "Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in c:\\users\\omri\\appdata\\roaming\\python\\python37\\site-packages (from gensim) (1.9.0)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gensim) (1.12.0)\n",
      "Requirement already satisfied, skipping upgrade: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.21.0)\n",
      "Requirement already satisfied, skipping upgrade: boto>=2.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (2.49.0)\n",
      "Requirement already satisfied, skipping upgrade: boto3 in c:\\programdata\\anaconda3\\lib\\site-packages (from smart-open>=1.8.1->gensim) (1.9.110)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2019.3.9)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (1.24.1)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->smart-open>=1.8.1->gensim) (2.8)\n",
      "Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.9.4)\n",
      "Requirement already satisfied, skipping upgrade: s3transfer<0.3.0,>=0.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (0.2.1)\n",
      "Requirement already satisfied, skipping upgrade: botocore<1.13.0,>=1.12.110 in c:\\programdata\\anaconda3\\lib\\site-packages (from boto3->smart-open>=1.8.1->gensim) (1.12.234)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.110->boto3->smart-open>=1.8.1->gensim) (2.8.0)\n",
      "Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from botocore<1.13.0,>=1.12.110->boto3->smart-open>=1.8.1->gensim) (0.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained word embeddings using Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import Sentence, WordEmbeddings\n",
    "glove_embedding = WordEmbeddings('glove')\n",
    "\n",
    "sentence = Sentence('The grass is green .')\n",
    "\n",
    "glove_embedding.embed(sentence)\n",
    "for token in sentence:\n",
    "    print(token)\n",
    "    print(token.embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Task: Compare the embeddings obtained using GloVe for the same word in different context (ie different sentences). Are they equal or different?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence embedding using the average of word vectors\n",
    "Now, let's average the vectors into a single vector that would represent our entire document, and use it for classification. We'll build a Logistic Regression classifier on top of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def get_sentence_embedding(sentence):\n",
    "    sentence = Sentence(sentence)\n",
    "    glove_embedding.embed(sentence)\n",
    "    sentence_embedding = np.mean( [np.array(token.embedding) for token in sentence], axis=0)\n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.48264474,  0.33375996,  0.348696  , -0.5163    ,  0.191962  ,\n",
       "        0.12714759,  0.013061  ,  0.1766614 , -0.1873308 , -0.093839  ,\n",
       "        0.0488024 , -0.0484856 ,  0.314986  ,  0.031634  ,  0.2535662 ,\n",
       "       -0.059972  ,  0.38505   ,  0.06304   ,  0.027378  ,  0.06385148,\n",
       "       -0.1046188 ,  0.131214  ,  0.39698398,  0.0049592 ,  0.48706597,\n",
       "        0.27059498,  0.0188544 , -0.780686  , -0.160654  , -0.0207716 ,\n",
       "       -0.2985124 ,  0.521548  ,  0.371312  ,  0.0037584 ,  0.24874802,\n",
       "        0.3579286 , -0.187218  ,  0.484008  ,  0.1211252 ,  0.0338024 ,\n",
       "       -0.32039762, -0.578998  ,  0.1858078 , -0.27883598,  0.07773139,\n",
       "       -0.14281002,  0.23905559, -0.13043599, -0.1817726 , -0.49833995,\n",
       "       -0.10820474, -0.30922002,  0.285602  ,  1.1599319 , -0.49102196,\n",
       "       -2.58022   ,  0.021746  ,  0.043806  ,  1.479552  ,  0.427112  ,\n",
       "       -0.02804599,  0.67730397, -0.0862168 ,  0.305978  ,  1.0884    ,\n",
       "       -0.21497002,  0.2661428 , -0.022402  ,  0.3063696 , -0.2959406 ,\n",
       "       -0.04430168, -0.124852  , -0.3095786 , -0.37071198,  0.2658556 ,\n",
       "        0.01379652,  0.1408166 ,  0.0865896 , -0.61099005,  0.25847322,\n",
       "        0.569286  ,  0.05893   , -0.656514  ,  0.1472954 , -0.85989   ,\n",
       "       -0.23183   ,  0.043911  , -0.21173999,  0.36706018,  0.13562599,\n",
       "       -0.0454518 , -0.6721238 , -0.32438502,  0.53062   , -0.48571223,\n",
       "       -0.01712   , -0.4413198 , -0.288836  ,  0.69392604,  0.3024668 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentence_embedding('The grass is green .')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load our own data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "clf = linear_model.LogisticRegression(C=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "vectors = np.array([get_sentence_embedding(x) for x in df['text']])\n",
    "y_truth = df['label']\n",
    "clf.fit(vectors, y_truth)\n",
    "\n",
    "y_predict = clf.predict(vectors)\n",
    "metrics.accuracy_score(y_truth, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's check the performance on our test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7087812901155326"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/val.csv')\n",
    "vectors = np.array([get_sentence_embedding(x) for x in df['text']])\n",
    "y_truth = df['label']\n",
    "y_predict = clf.predict(vectors)\n",
    "metrics.accuracy_score(y_truth, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "   rec.sport.baseball       0.69      0.69      0.69        16\n",
      "     rec.sport.hockey       0.71      0.75      0.73        20\n",
      "   talk.politics.guns       0.79      0.68      0.73        22\n",
      "talk.politics.mideast       0.65      0.72      0.68        18\n",
      "\n",
      "            micro avg       0.71      0.71      0.71        76\n",
      "            macro avg       0.71      0.71      0.71        76\n",
      "         weighted avg       0.72      0.71      0.71        76\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_truth, y_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
